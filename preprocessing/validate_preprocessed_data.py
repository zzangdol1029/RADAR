#!/usr/bin/env python3
"""
ì „ì²˜ë¦¬ëœ ë°ì´í„° ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

ì „ì²˜ë¦¬ëœ JSON íŒŒì¼ë“¤ì˜ í’ˆì§ˆì„ ê²€ì¦í•©ë‹ˆë‹¤:
1. íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ë° JSON í˜•ì‹ ê²€ì¦
2. ë°ì´í„° êµ¬ì¡° ê²€ì¦
3. í†µê³„ ì •ë³´ ìˆ˜ì§‘
4. ìƒ˜í”Œ ë°ì´í„° í™•ì¸
"""

import json
import os
from pathlib import Path
from typing import Dict, List, Any, Optional
from collections import defaultdict, Counter
import sys


class PreprocessedDataValidator:
    """ì „ì²˜ë¦¬ëœ ë°ì´í„° ê²€ì¦ í´ë˜ìŠ¤"""
    
    REQUIRED_FIELDS = [
        'session_id',
        'event_sequence',
        'token_ids',
        'attention_mask',
        'has_error',
        'has_warn',
        'service_name',
        'original_logs',
        'simplified_text'
    ]
    
    def __init__(self, output_dir: str = "output"):
        self.output_dir = Path(output_dir)
        self.errors = []
        self.warnings = []
        self.stats = {
            'total_files': 0,
            'valid_files': 0,
            'invalid_files': 0,
            'total_sessions': 0,
            'total_events': 0,
            'unique_event_ids': set(),
            'service_names': Counter(),
            'dates': [],
            'error_sessions': 0,
            'warn_sessions': 0,
            'file_sizes': {},
            'sample_sessions': []
        }
    
    def validate_file(self, file_path: Path) -> Dict[str, Any]:
        """ë‹¨ì¼ íŒŒì¼ ê²€ì¦"""
        result = {
            'file': str(file_path),
            'valid': False,
            'errors': [],
            'warnings': [],
            'sessions': 0,
            'file_size_mb': 0
        }
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not file_path.exists():
            result['errors'].append(f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
            return result
        
        # íŒŒì¼ í¬ê¸°
        file_size = file_path.stat().st_size
        result['file_size_mb'] = file_size / (1024 * 1024)
        self.stats['file_sizes'][str(file_path)] = result['file_size_mb']
        
        # JSON í˜•ì‹ ê²€ì¦
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except json.JSONDecodeError as e:
            result['errors'].append(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return result
        except Exception as e:
            result['errors'].append(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            return result
        
        # ë°°ì—´ í˜•ì‹ í™•ì¸
        if not isinstance(data, list):
            result['errors'].append(f"ë°ì´í„°ê°€ ë°°ì—´ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤: {type(data)}")
            return result
        
        result['sessions'] = len(data)
        self.stats['total_sessions'] += len(data)
        
        # ê° ì„¸ì…˜ ê²€ì¦
        for idx, session in enumerate(data):
            session_errors = self._validate_session(session, idx)
            result['errors'].extend(session_errors)
            
            if not session_errors:
                # í†µê³„ ìˆ˜ì§‘
                self._collect_stats(session)
        
        # ìƒ˜í”Œ ì„¸ì…˜ ì €ì¥ (ì²˜ìŒ 3ê°œ)
        if len(data) > 0 and len(self.stats['sample_sessions']) < 3:
            self.stats['sample_sessions'].append(data[0])
        
        result['valid'] = len(result['errors']) == 0
        return result
    
    def _validate_session(self, session: Dict[str, Any], index: int) -> List[str]:
        """ë‹¨ì¼ ì„¸ì…˜ ê²€ì¦"""
        errors = []
        
        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        for field in self.REQUIRED_FIELDS:
            if field not in session:
                errors.append(f"ì„¸ì…˜ {index}: í•„ìˆ˜ í•„ë“œ '{field}'ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # ë°ì´í„° íƒ€ì… ê²€ì¦
        if 'event_sequence' in session:
            if not isinstance(session['event_sequence'], list):
                errors.append(f"ì„¸ì…˜ {index}: 'event_sequence'ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹™ë‹ˆë‹¤")
            elif len(session['event_sequence']) == 0:
                errors.append(f"ì„¸ì…˜ {index}: 'event_sequence'ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        if 'token_ids' in session:
            if not isinstance(session['token_ids'], list):
                errors.append(f"ì„¸ì…˜ {index}: 'token_ids'ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹™ë‹ˆë‹¤")
            elif len(session['token_ids']) == 0:
                errors.append(f"ì„¸ì…˜ {index}: 'token_ids'ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        if 'attention_mask' in session:
            if not isinstance(session['attention_mask'], list):
                errors.append(f"ì„¸ì…˜ {index}: 'attention_mask'ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹™ë‹ˆë‹¤")
            elif 'token_ids' in session and len(session['attention_mask']) != len(session['token_ids']):
                errors.append(f"ì„¸ì…˜ {index}: 'attention_mask' ê¸¸ì´ê°€ 'token_ids'ì™€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        
        # ê°’ ë²”ìœ„ ê²€ì¦
        if 'token_ids' in session and isinstance(session['token_ids'], list):
            if session['token_ids'][0] != 101:  # [CLS] í† í°
                errors.append(f"ì„¸ì…˜ {index}: 'token_ids'ê°€ [CLS] í† í°(101)ìœ¼ë¡œ ì‹œì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            if session['token_ids'][-1] != 102 and 102 in session['token_ids']:  # [SEP] í† í°
                sep_idx = session['token_ids'].index(102) if 102 in session['token_ids'] else -1
                if sep_idx < len(session['token_ids']) - 1:
                    # [SEP] ì´í›„ì—ë§Œ íŒ¨ë”©ì´ ìˆì–´ì•¼ í•¨
                    pass
        
        return errors
    
    def _collect_stats(self, session: Dict[str, Any]):
        """í†µê³„ ì •ë³´ ìˆ˜ì§‘"""
        # Event ID ìˆ˜ì§‘
        if 'event_sequence' in session:
            for event_id in session['event_sequence']:
                self.stats['unique_event_ids'].add(event_id)
                self.stats['total_events'] += 1
        
        # ì„œë¹„ìŠ¤ëª… ìˆ˜ì§‘
        if 'service_name' in session:
            self.stats['service_names'][session['service_name']] += 1
        
        # ì—ëŸ¬/ê²½ê³  ì„¸ì…˜ ìˆ˜ì§‘
        if session.get('has_error', False):
            self.stats['error_sessions'] += 1
        if session.get('has_warn', False):
            self.stats['warn_sessions'] += 1
    
    def validate_all(self) -> Dict[str, Any]:
        """ëª¨ë“  ì „ì²˜ë¦¬ íŒŒì¼ ê²€ì¦"""
        print("=" * 80)
        print("ì „ì²˜ë¦¬ëœ ë°ì´í„° ê²€ì¦ ì‹œì‘")
        print("=" * 80)
        print()
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ í™•ì¸
        if not self.output_dir.exists():
            print(f"âŒ ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.output_dir}")
            return {'valid': False, 'error': 'Output directory not found'}
        
        # JSON íŒŒì¼ ì°¾ê¸°
        json_files = sorted(self.output_dir.glob("preprocessed_logs_*.json"))
        self.stats['total_files'] = len(json_files)
        
        if len(json_files) == 0:
            print(f"âŒ ì „ì²˜ë¦¬ëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.output_dir}")
            return {'valid': False, 'error': 'No preprocessed files found'}
        
        print(f"ë°œê²¬ëœ íŒŒì¼ ìˆ˜: {len(json_files)}ê°œ")
        print()
        
        # ê° íŒŒì¼ ê²€ì¦
        results = []
        for json_file in json_files:
            print(f"ê²€ì¦ ì¤‘: {json_file.name}...", end=' ', flush=True)
            result = self.validate_file(json_file)
            results.append(result)
            
            if result['valid']:
                print(f"âœ… ({result['sessions']}ê°œ ì„¸ì…˜, {result['file_size_mb']:.2f}MB)")
                self.stats['valid_files'] += 1
            else:
                print(f"âŒ ({len(result['errors'])}ê°œ ì˜¤ë¥˜)")
                self.stats['invalid_files'] += 1
                self.errors.extend(result['errors'])
        
        print()
        print("=" * 80)
        print("ê²€ì¦ ê²°ê³¼ ìš”ì•½")
        print("=" * 80)
        print()
        
        # í†µê³„ ì¶œë ¥
        self._print_summary()
        
        # ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥
        if self.stats['sample_sessions']:
            print()
            print("=" * 80)
            print("ìƒ˜í”Œ ì„¸ì…˜ ë°ì´í„° (ì²« ë²ˆì§¸ íŒŒì¼ì˜ ì²« ë²ˆì§¸ ì„¸ì…˜)")
            print("=" * 80)
            sample = self.stats['sample_sessions'][0]
            print(json.dumps(sample, ensure_ascii=False, indent=2)[:1000] + "...")
        
        return {
            'valid': self.stats['invalid_files'] == 0,
            'stats': self.stats,
            'errors': self.errors,
            'warnings': self.warnings
        }
    
    def _print_summary(self):
        """í†µê³„ ìš”ì•½ ì¶œë ¥"""
        print(f"ğŸ“ ì´ íŒŒì¼ ìˆ˜: {self.stats['total_files']}ê°œ")
        print(f"   âœ… ìœ íš¨í•œ íŒŒì¼: {self.stats['valid_files']}ê°œ")
        print(f"   âŒ ë¬´íš¨í•œ íŒŒì¼: {self.stats['invalid_files']}ê°œ")
        print()
        
        print(f"ğŸ“Š ì´ ì„¸ì…˜ ìˆ˜: {self.stats['total_sessions']:,}ê°œ")
        print(f"   âš ï¸  ì—ëŸ¬ í¬í•¨ ì„¸ì…˜: {self.stats['error_sessions']:,}ê°œ ({self.stats['error_sessions']/max(self.stats['total_sessions'],1)*100:.1f}%)")
        print(f"   âš ï¸  ê²½ê³  í¬í•¨ ì„¸ì…˜: {self.stats['warn_sessions']:,}ê°œ ({self.stats['warn_sessions']/max(self.stats['total_sessions'],1)*100:.1f}%)")
        print()
        
        print(f"ğŸ”¢ ì´ ì´ë²¤íŠ¸ ìˆ˜: {self.stats['total_events']:,}ê°œ")
        print(f"   ê³ ìœ  Event ID ìˆ˜: {len(self.stats['unique_event_ids']):,}ê°œ")
        print()
        
        print(f"ğŸ·ï¸  ì„œë¹„ìŠ¤ë³„ ì„¸ì…˜ ìˆ˜:")
        for service, count in self.stats['service_names'].most_common(10):
            print(f"   - {service}: {count:,}ê°œ")
        if len(self.stats['service_names']) > 10:
            print(f"   ... ì™¸ {len(self.stats['service_names']) - 10}ê°œ ì„œë¹„ìŠ¤")
        print()
        
        # íŒŒì¼ í¬ê¸° í†µê³„
        if self.stats['file_sizes']:
            total_size = sum(self.stats['file_sizes'].values())
            avg_size = total_size / len(self.stats['file_sizes'])
            max_size = max(self.stats['file_sizes'].values())
            min_size = min(self.stats['file_sizes'].values())
            
            print(f"ğŸ’¾ íŒŒì¼ í¬ê¸° í†µê³„:")
            print(f"   ì´ í¬ê¸°: {total_size:.2f}MB")
            print(f"   í‰ê·  í¬ê¸°: {avg_size:.2f}MB")
            print(f"   ìµœëŒ€ í¬ê¸°: {max_size:.2f}MB")
            print(f"   ìµœì†Œ í¬ê¸°: {min_size:.2f}MB")
            print()
        
        # ì˜¤ë¥˜ ì¶œë ¥
        if self.errors:
            print("=" * 80)
            print("âŒ ë°œê²¬ëœ ì˜¤ë¥˜:")
            print("=" * 80)
            for error in self.errors[:20]:  # ìµœëŒ€ 20ê°œë§Œ ì¶œë ¥
                print(f"  - {error}")
            if len(self.errors) > 20:
                print(f"  ... ì™¸ {len(self.errors) - 20}ê°œ ì˜¤ë¥˜")
            print()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ì „ì²˜ë¦¬ëœ ë°ì´í„° ê²€ì¦')
    parser.add_argument('--output-dir', type=str, default='output',
                       help='ì „ì²˜ë¦¬ëœ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: output)')
    parser.add_argument('--file', type=str, default=None,
                       help='íŠ¹ì • íŒŒì¼ë§Œ ê²€ì¦ (ì„ íƒì‚¬í•­)')
    
    args = parser.parse_args()
    
    # ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
    base_dir = Path(__file__).parent
    output_dir = base_dir / args.output_dir
    
    validator = PreprocessedDataValidator(output_dir=str(output_dir))
    
    if args.file:
        # íŠ¹ì • íŒŒì¼ë§Œ ê²€ì¦
        file_path = output_dir / args.file
        result = validator.validate_file(file_path)
        print(json.dumps(result, ensure_ascii=False, indent=2))
    else:
        # ëª¨ë“  íŒŒì¼ ê²€ì¦
        result = validator.validate_all()
        
        # ì¢…ë£Œ ì½”ë“œ
        sys.exit(0 if result['valid'] else 1)


if __name__ == '__main__':
    main()

