# Loss ëª©í‘œ ë° ì´ìƒ íƒì§€ ì„±ëŠ¥ ê°€ì´ë“œ

## ğŸ“Š Lossì™€ ì´ìƒ íƒì§€ ì„±ëŠ¥ì˜ ê´€ê³„

### Lossì˜ ì˜ë¯¸

**MLM Loss**ëŠ” ëª¨ë¸ì´ ë§ˆìŠ¤í‚¹ëœ í† í°ì„ ì–¼ë§ˆë‚˜ ì˜ ì˜ˆì¸¡í•˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

```
Loss = -log(P(ì •ë‹µ í† í° | ë¬¸ë§¥))
```

- **ë‚®ì€ Loss**: ëª¨ë¸ì´ íŒ¨í„´ì„ ì˜ í•™ìŠµ â†’ ì •ìƒ íŒ¨í„´ ì˜ˆì¸¡ ì‰¬ì›€
- **ë†’ì€ Loss**: ëª¨ë¸ì´ íŒ¨í„´ì„ ëª» í•™ìŠµ â†’ ì˜ˆì¸¡ ì–´ë ¤ì›€

### ì´ìƒ ì ìˆ˜ ê³„ì‚°

```python
# ì´ìƒ ì ìˆ˜ = -log(ì˜ˆì¸¡ í™•ë¥ )
anomaly_score = -log(P(ì‹¤ì œ í† í° | ë¬¸ë§¥))
```

- **ì •ìƒ íŒ¨í„´**: ë†’ì€ ì˜ˆì¸¡ í™•ë¥  â†’ ë‚®ì€ ì´ìƒ ì ìˆ˜
- **ì´ìƒ íŒ¨í„´**: ë‚®ì€ ì˜ˆì¸¡ í™•ë¥  â†’ ë†’ì€ ì´ìƒ ì ìˆ˜

## ğŸ¯ Loss ëª©í‘œ ê°€ì´ë“œ

### ì¼ë°˜ì ì¸ Loss ëª©í‘œ

| Loss ë²”ìœ„ | í•™ìŠµ ìƒíƒœ | ì´ìƒ íƒì§€ ì„±ëŠ¥ | ê¶Œì¥ ì‚¬í•­ |
|----------|----------|--------------|----------|
| **3.0 ì´ìƒ** | ì´ˆê¸° ë‹¨ê³„ | âŒ ë¶ˆê°€ëŠ¥ | í•™ìŠµ ê³„ì† í•„ìš” |
| **2.0 ~ 3.0** | ê¸°ë³¸ í•™ìŠµ | âš ï¸ ì œí•œì  | ê¸°ë³¸ íŒ¨í„´ë§Œ í•™ìŠµ |
| **1.5 ~ 2.0** | ì¢‹ì€ í•™ìŠµ | âœ… ê¸°ë³¸ ê°€ëŠ¥ | ì‹¤ìš©ì  ì‚¬ìš© ê°€ëŠ¥ |
| **1.0 ~ 1.5** | ë§¤ìš° ì¢‹ìŒ | âœ… ì¢‹ì€ ì„±ëŠ¥ | í”„ë¡œë•ì…˜ ì‚¬ìš© ê¶Œì¥ |
| **0.5 ~ 1.0** | ìš°ìˆ˜ | âœ… ë§¤ìš° ì¢‹ìŒ | ìµœì  ì„±ëŠ¥ |
| **0.5 ë¯¸ë§Œ** | ê³¼ì í•© ê°€ëŠ¥ | âš ï¸ ì£¼ì˜ í•„ìš” | ê²€ì¦ ë°ì´í„° í™•ì¸ |

### í˜„ì¬ í•™ìŠµ ìƒíƒœ ë¶„ì„

**í˜„ì¬ Loss ì¶”ì´:**
- Step 100: Loss=3.6964, Avg=5.6560
- Step 500: Loss=1.9576, Avg=3.2244
- Step 1000: Loss=1.7651, Avg=2.5771
- Step 1535: Loss=1.4797, Avg=2.2795

**ì˜ˆìƒ ì™„ë£Œ ì‹œì :**
- ì—í­ 1 ì™„ë£Œ: Avg Loss â‰ˆ **1.5 ~ 2.0** ì˜ˆìƒ
- ì—í­ 5 ì™„ë£Œ: Avg Loss â‰ˆ **1.0 ~ 1.5** ì˜ˆìƒ
- ì—í­ 10 ì™„ë£Œ: Avg Loss â‰ˆ **0.8 ~ 1.2** ì˜ˆìƒ

## ğŸ“ˆ Lossë³„ ì˜ˆìƒ ì„±ëŠ¥

### Loss 2.0 ~ 3.0 (ê¸°ë³¸ í•™ìŠµ)

**íŠ¹ì§•:**
- ê¸°ë³¸ì ì¸ íŒ¨í„´ í•™ìŠµ ì™„ë£Œ
- ì¼ë°˜ì ì¸ ì •ìƒ íŒ¨í„´ ì¸ì‹ ê°€ëŠ¥

**ì´ìƒ íƒì§€ ì„±ëŠ¥:**
- ì •í™•ë„: 60-70%
- ì •ë°€ë„: 50-60%
- ì¬í˜„ìœ¨: 40-50%

**ì‚¬ìš© ê°€ëŠ¥ì„±:**
- âœ… ê°œë°œ/í…ŒìŠ¤íŠ¸ í™˜ê²½
- âš ï¸ í”„ë¡œë•ì…˜: ì œí•œì  ì‚¬ìš©

### Loss 1.5 ~ 2.0 (ì¢‹ì€ í•™ìŠµ) â­ ê¶Œì¥

**íŠ¹ì§•:**
- ì£¼ìš” íŒ¨í„´ í•™ìŠµ ì™„ë£Œ
- ëŒ€ë¶€ë¶„ì˜ ì •ìƒ íŒ¨í„´ ì¸ì‹ ê°€ëŠ¥

**ì´ìƒ íƒì§€ ì„±ëŠ¥:**
- ì •í™•ë„: 75-85%
- ì •ë°€ë„: 70-80%
- ì¬í˜„ìœ¨: 65-75%

**ì‚¬ìš© ê°€ëŠ¥ì„±:**
- âœ… í”„ë¡œë•ì…˜ ì‚¬ìš© ê°€ëŠ¥
- âœ… ì‹¤ìš©ì ì¸ ì´ìƒ íƒì§€ ê°€ëŠ¥

### Loss 1.0 ~ 1.5 (ë§¤ìš° ì¢‹ìŒ) â­â­ ìµœì 

**íŠ¹ì§•:**
- íŒ¨í„´ í•™ìŠµ ë§¤ìš° ìš°ìˆ˜
- ë³µì¡í•œ íŒ¨í„´ë„ ì¸ì‹ ê°€ëŠ¥

**ì´ìƒ íƒì§€ ì„±ëŠ¥:**
- ì •í™•ë„: 85-92%
- ì •ë°€ë„: 80-88%
- ì¬í˜„ìœ¨: 75-85%

**ì‚¬ìš© ê°€ëŠ¥ì„±:**
- âœ… í”„ë¡œë•ì…˜ ì‚¬ìš© ê¶Œì¥
- âœ… ë†’ì€ ì‹ ë¢°ë„

### Loss 0.5 ~ 1.0 (ìš°ìˆ˜)

**íŠ¹ì§•:**
- ê±°ì˜ ì™„ë²½í•œ íŒ¨í„´ í•™ìŠµ
- ë¯¸ì„¸í•œ ì´ìƒë„ íƒì§€ ê°€ëŠ¥

**ì´ìƒ íƒì§€ ì„±ëŠ¥:**
- ì •í™•ë„: 90-95%
- ì •ë°€ë„: 85-92%
- ì¬í˜„ìœ¨: 80-90%

**ì‚¬ìš© ê°€ëŠ¥ì„±:**
- âœ… ìµœê³  ì„±ëŠ¥
- âš ï¸ ê³¼ì í•© ê°€ëŠ¥ì„± í™•ì¸ í•„ìš”

## ğŸ” ì‹¤ì œ ì„±ëŠ¥ í‰ê°€ ë°©ë²•

### Lossë§Œìœ¼ë¡œëŠ” ë¶€ì¡±í•©ë‹ˆë‹¤!

**LossëŠ” í•™ìŠµ ì§„í–‰ ìƒí™©ì˜ ì§€í‘œì¼ ë¿, ì‹¤ì œ ì´ìƒ íƒì§€ ì„±ëŠ¥ì€ ë³„ë„ë¡œ ì¸¡ì •í•´ì•¼ í•©ë‹ˆë‹¤.**

### 1ë‹¨ê³„: ê²€ì¦ ë°ì´í„°ì…‹ ì¤€ë¹„

```python
# ì •ìƒ/ì´ìƒ ë ˆì´ë¸”ì´ ìˆëŠ” ê²€ì¦ ë°ì´í„° í•„ìš”
validation_data = {
    'normal_sessions': [...],  # ì •ìƒ ì„¸ì…˜
    'anomaly_sessions': [...],  # ì´ìƒ ì„¸ì…˜
}
```

### 2ë‹¨ê³„: ì´ìƒ ì ìˆ˜ ê³„ì‚°

```python
# í•™ìŠµëœ ëª¨ë¸ë¡œ ì´ìƒ ì ìˆ˜ ê³„ì‚°
normal_scores = model.predict_anomaly_score(normal_sessions)
anomaly_scores = model.predict_anomaly_score(anomaly_sessions)
```

### 3ë‹¨ê³„: ì„ê³„ê°’ ì„¤ì •

```python
# ì •ìƒ/ì´ìƒ ì ìˆ˜ ë¶„í¬ í™•ì¸
import numpy as np

normal_mean = np.mean(normal_scores)
normal_std = np.std(normal_scores)
anomaly_mean = np.mean(anomaly_scores)

# ì„ê³„ê°’ ì„¤ì • (ì˜ˆ: ì •ìƒ í‰ê·  + 2*í‘œì¤€í¸ì°¨)
threshold = normal_mean + 2 * normal_std
```

### 4ë‹¨ê³„: ì„±ëŠ¥ í‰ê°€

```python
# ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨ ê³„ì‚°
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

predictions = (scores >= threshold).astype(int)
labels = (is_anomaly).astype(int)

accuracy = accuracy_score(labels, predictions)
precision = precision_score(labels, predictions)
recall = recall_score(labels, predictions)
f1 = f1_score(labels, predictions)
```

## ğŸ’¡ ì‹¤ìš©ì ì¸ ê°€ì´ë“œ

### í˜„ì¬ í•™ìŠµ ìƒíƒœ ê¸°ì¤€

**í˜„ì¬ Loss: 2.2795 (í‰ê· )**

**ì˜ˆìƒ ì„±ëŠ¥:**
- Loss 2.0 ~ 2.5: ê¸°ë³¸ì ì¸ ì´ìƒ íƒì§€ ê°€ëŠ¥
- Loss 1.5 ~ 2.0: ì‹¤ìš©ì ì¸ ì´ìƒ íƒì§€ ê°€ëŠ¥ â­
- Loss 1.0 ~ 1.5: ìš°ìˆ˜í•œ ì´ìƒ íƒì§€ ì„±ëŠ¥ â­â­

### ê¶Œì¥ ì‚¬í•­

#### 1. ì—í­ 1 ì™„ë£Œ í›„ (Loss â‰ˆ 1.5 ~ 2.0)

```bash
# ì²´í¬í¬ì¸íŠ¸ë¡œ ì¶”ë¡  í…ŒìŠ¤íŠ¸
python3 inference.py \
  --checkpoint checkpoints/checkpoints/checkpoint_step_19252.pt \
  --input ../preprocessing/output/preprocessed_logs_2025-12-08.json \
  --output test_results_epoch1.json
```

**í™•ì¸ ì‚¬í•­:**
- ì´ìƒ ì ìˆ˜ ë¶„í¬ í™•ì¸
- ì •ìƒ/ì´ìƒ êµ¬ë¶„ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸

#### 2. ì—í­ 5 ì™„ë£Œ í›„ (Loss â‰ˆ 1.0 ~ 1.5)

```bash
# ë” ì •í™•í•œ ì„±ëŠ¥ í‰ê°€
python3 inference.py \
  --checkpoint checkpoints/checkpoints/checkpoint_step_96260.pt \
  --input validation_data.json \
  --threshold 2.0
```

**í™•ì¸ ì‚¬í•­:**
- ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨ ì¸¡ì •
- ì„ê³„ê°’ ìµœì í™”

#### 3. ì—í­ 10 ì™„ë£Œ í›„ (Loss â‰ˆ 0.8 ~ 1.2)

```bash
# ìµœì¢… ì„±ëŠ¥ í‰ê°€
python3 inference.py \
  --checkpoint checkpoints/checkpoints/best_model.pt \
  --input test_data.json \
  --threshold 1.5
```

**í™•ì¸ ì‚¬í•­:**
- ìµœì¢… ì„±ëŠ¥ í™•ì¸
- í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„

## ğŸ¯ Loss ëª©í‘œ ìš”ì•½

### ìµœì†Œ ëª©í‘œ (ê¸°ë³¸ ì‚¬ìš©)

- **Loss < 2.0**: ê¸°ë³¸ì ì¸ ì´ìƒ íƒì§€ ê°€ëŠ¥
- **ì—í­**: 1-2 ì—í­ ì™„ë£Œ

### ê¶Œì¥ ëª©í‘œ (ì‹¤ìš©ì  ì‚¬ìš©) â­

- **Loss < 1.5**: ì‹¤ìš©ì ì¸ ì´ìƒ íƒì§€ ê°€ëŠ¥
- **ì—í­**: 3-5 ì—í­ ì™„ë£Œ

### ìµœì  ëª©í‘œ (ìš°ìˆ˜í•œ ì„±ëŠ¥) â­â­

- **Loss < 1.0**: ìš°ìˆ˜í•œ ì´ìƒ íƒì§€ ì„±ëŠ¥
- **ì—í­**: 7-10 ì—í­ ì™„ë£Œ

## âš ï¸ ì£¼ì˜ì‚¬í•­

### 1. Lossë§Œìœ¼ë¡œ íŒë‹¨í•˜ì§€ ë§ˆì„¸ìš”

- LossëŠ” í•™ìŠµ ì§„í–‰ ìƒí™©ì˜ ì§€í‘œì¼ ë¿
- ì‹¤ì œ ì„±ëŠ¥ì€ ê²€ì¦ ë°ì´í„°ë¡œ ì¸¡ì •í•´ì•¼ í•¨

### 2. ê³¼ì í•© í™•ì¸

- Lossê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ (0.5 ë¯¸ë§Œ) ê³¼ì í•© ê°€ëŠ¥ì„±
- ê²€ì¦ ë°ì´í„°ì—ì„œ ì„±ëŠ¥ í™•ì¸ í•„ìš”

### 3. ë°ì´í„° íŠ¹ì„± ê³ ë ¤

- ë¡œê·¸ ë°ì´í„°ì˜ ë³µì¡ë„ì— ë”°ë¼ Loss ëª©í‘œê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ
- ì‹¤ì œ ë°ì´í„°ë¡œ ì„±ëŠ¥ í‰ê°€ê°€ ê°€ì¥ ì¤‘ìš”

## ğŸ“ ê²°ë¡ 

### í˜„ì¬ ìƒíƒœ

- **í˜„ì¬ Loss**: 2.2795 (í‰ê· )
- **ì˜ˆìƒ ì™„ë£Œ**: ì—í­ 1 ì™„ë£Œ ì‹œ Loss â‰ˆ 1.5 ~ 2.0
- **ì˜ˆìƒ ì„±ëŠ¥**: ê¸°ë³¸ì ì¸ ì´ìƒ íƒì§€ ê°€ëŠ¥

### ê¶Œì¥ ëª©í‘œ

- **Loss < 1.5**: ì‹¤ìš©ì ì¸ ì´ìƒ íƒì§€ ê°€ëŠ¥ â­
- **ì—í­ 3-5 ì™„ë£Œ**: ê¶Œì¥
- **Loss < 1.0**: ìš°ìˆ˜í•œ ì„±ëŠ¥ â­â­
- **ì—í­ 7-10 ì™„ë£Œ**: ìµœì 

### ë‹¤ìŒ ë‹¨ê³„

1. **ì—í­ 1 ì™„ë£Œ í›„**: ê¸°ë³¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
2. **ì—í­ 3-5 ì™„ë£Œ í›„**: ì‹¤ìš©ì  ì„±ëŠ¥ í™•ì¸
3. **ì—í­ 10 ì™„ë£Œ í›„**: ìµœì¢… ì„±ëŠ¥ í‰ê°€ ë° ë°°í¬

**í˜„ì¬ í•™ìŠµì´ ì˜ ì§„í–‰ë˜ê³  ìˆìœ¼ë‹ˆ, ì—í­ 1 ì™„ë£Œ í›„ ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”!** âœ…

