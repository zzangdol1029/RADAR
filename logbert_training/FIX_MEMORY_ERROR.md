# CUDA Out of Memory ì˜¤ë¥˜ í•´ê²° ê°€ì´ë“œ

## ğŸ”´ ì˜¤ë¥˜ ë°œìƒ

```
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.50 GiB. 
GPU 0 has a total capacity of 31.73 GiB of which 190.62 MiB is free.
```

## âœ… í•´ê²° ë°©ë²•

### ë°©ë²• 1: ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸° (ê¶Œì¥)

ë°°ì¹˜ í¬ê¸°ë¥¼ 64 ë˜ëŠ” 48ë¡œ ì¤„ì…ë‹ˆë‹¤:

```bash
# ë°°ì¹˜ í¬ê¸° 64ë¡œ ì‹¤í–‰
python3 train_server.py --config training_config_dgx.yaml --batch-size 64

# ë˜ëŠ” ë°°ì¹˜ í¬ê¸° 48ë¡œ ì‹¤í–‰ (ë” ì•ˆì „)
python3 train_server.py --config training_config_dgx.yaml --batch-size 48
```

### ë°©ë²• 2: ì„¤ì • íŒŒì¼ ìˆ˜ì •

`training_config_dgx.yaml` íŒŒì¼ì„ ìˆ˜ì •:

```yaml
training:
  batch_size: 64  # 128ì—ì„œ 64ë¡œ ë³€ê²½
```

ê·¸ ë‹¤ìŒ ë‹¤ì‹œ ì‹¤í–‰:

```bash
python3 train_server.py --config training_config_dgx.yaml
```

### ë°©ë²• 3: GPU ë©”ëª¨ë¦¬ ì •ë¦¬ í›„ ì¬ì‹¤í–‰

```bash
# ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
kill $(cat logs/training_*.pid 2>/dev/null) 2>/dev/null

# GPU ë©”ëª¨ë¦¬ ì •ë¦¬ (í•„ìš”ì‹œ)
# ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ê°€ GPUë¥¼ ì‚¬ìš© ì¤‘ì¼ ìˆ˜ ìˆìŒ
nvidia-smi

# ë‹¤ì‹œ ì‹¤í–‰ (ì‘ì€ ë°°ì¹˜ í¬ê¸°ë¡œ)
python3 train_server.py --config training_config_dgx.yaml --batch-size 64
```

## ğŸ“Š ë°°ì¹˜ í¬ê¸°ë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ì‹¤ì œ ì¸¡ì •)

| ë°°ì¹˜ í¬ê¸° | GPU ë©”ëª¨ë¦¬ ì‚¬ìš© | ì•ˆì „ì„± | ê¶Œì¥ |
|----------|---------------|--------|------|
| 32 | ~12-15GB | âœ… ë§¤ìš° ì•ˆì „ | ë³´ìˆ˜ì  |
| **48** | **~16-20GB** | **âœ… ì•ˆì „** | **ê¶Œì¥** |
| **64** | **~18-22GB** | **âœ… ì•ˆì „** | **ê¶Œì¥** |
| 128 | ~30GB+ | âŒ ë©”ëª¨ë¦¬ ë¶€ì¡± | ë¹„ê¶Œì¥ |

## ğŸš€ ê¶Œì¥ ì‹¤í–‰ ëª…ë ¹ì–´

### ì•ˆì •ì ì¸ ì„¤ì • (ê¶Œì¥)

```bash
cd /home/zzangdol/RADAR-1/logbert_training

# ë°°ì¹˜ í¬ê¸° 64ë¡œ ì‹¤í–‰
python3 train_server.py --config training_config_dgx.yaml --batch-size 64
```

### ë” ì•ˆì „í•œ ì„¤ì •

```bash
# ë°°ì¹˜ í¬ê¸° 48ë¡œ ì‹¤í–‰
python3 train_server.py --config training_config_dgx.yaml --batch-size 48
```

### ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰

```bash
# ë°°ì¹˜ í¬ê¸° 64ë¡œ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
./run_training_background.sh --batch-size 64
```

## ğŸ“ˆ ì˜ˆìƒ í•™ìŠµ ì‹œê°„ (ë°°ì¹˜ í¬ê¸° ì¡°ì • í›„)

| ë°°ì¹˜ í¬ê¸° | ì—í­ë‹¹ ì‹œê°„ | 10 ì—í­ ì‹œê°„ |
|----------|-----------|------------|
| 32 | ~4ì‹œê°„ | ~40ì‹œê°„ |
| **48** | **~2.5ì‹œê°„** | **~25ì‹œê°„** |
| **64** | **~2.2ì‹œê°„** | **~22ì‹œê°„** |
| 128 | ~1.2ì‹œê°„ | ~12ì‹œê°„ (ë©”ëª¨ë¦¬ ë¶€ì¡±) |

## ğŸ” GPU ë©”ëª¨ë¦¬ í™•ì¸

í•™ìŠµ ì „ì— GPU ë©”ëª¨ë¦¬ë¥¼ í™•ì¸í•˜ì„¸ìš”:

```bash
# GPU ìƒíƒœ í™•ì¸
nvidia-smi

# ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ê°€ GPUë¥¼ ì‚¬ìš© ì¤‘ì¸ì§€ í™•ì¸
nvidia-smi --query-compute-apps=pid,process_name,used_memory --format=csv
```

## ğŸ’¡ ì¶”ê°€ ìµœì í™” ë°©ë²•

### 1. Gradient Accumulation ì‚¬ìš© (í–¥í›„ ì¶”ê°€ ê°€ëŠ¥)

ì‘ì€ ë°°ì¹˜ë¥¼ ì—¬ëŸ¬ ë²ˆ ëˆ„ì í•˜ì—¬ í° ë°°ì¹˜ íš¨ê³¼ë¥¼ ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
# ì˜ˆ: ë°°ì¹˜ 32ë¥¼ 2ë²ˆ ëˆ„ì  = ë°°ì¹˜ 64 íš¨ê³¼
accumulation_steps = 2
effective_batch_size = batch_size * accumulation_steps
```

### 2. Mixed Precision Training (í–¥í›„ ì¶”ê°€ ê°€ëŠ¥)

FP16ì„ ì‚¬ìš©í•˜ë©´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì ˆë°˜ìœ¼ë¡œ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()
with autocast():
    outputs = model(...)
```

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ í™•ì¸**: ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ê°€ GPU ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš© ì¤‘ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. **ë°ì´í„° í¬ê¸°**: ë°ì´í„°ì…‹ì´ í¬ë©´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì¦ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. **ëª¨ë¸ í¬ê¸°**: BERT-base ëª¨ë¸ì´ë¯€ë¡œ hidden_sizeë‚˜ layersë¥¼ ì¤„ì´ë©´ ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ë¹ ë¥¸ í•´ê²°

**ê°€ì¥ ë¹ ë¥¸ í•´ê²° ë°©ë²•:**

```bash
cd /home/zzangdol/RADAR-1/logbert_training

# ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ (ìˆëŠ” ê²½ìš°)
kill $(cat logs/training_*.pid 2>/dev/null) 2>/dev/null

# ë°°ì¹˜ í¬ê¸° 64ë¡œ ì¬ì‹¤í–‰
python3 train_server.py --config training_config_dgx.yaml --batch-size 64
```

ë˜ëŠ” ë°±ê·¸ë¼ìš´ë“œë¡œ:

```bash
./run_training_background.sh --batch-size 64
```

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
- [ ] GPU ë©”ëª¨ë¦¬ í™•ì¸ (`nvidia-smi`)
- [ ] ë°°ì¹˜ í¬ê¸° 64 ë˜ëŠ” 48ë¡œ ì„¤ì •
- [ ] ì¬ì‹¤í–‰
- [ ] ë¡œê·¸ ëª¨ë‹ˆí„°ë§ (`tail -f logs/training_*.log`)

