# BERT 전이 학습 가이드

## 전이 학습으로 가능한 것

### ✅ 가능한 것

#### 1. **Pre-trained 성능 확인**
- Pre-trained BERT가 이미 학습한 일반적인 언어 패턴 활용
- 로그 데이터에 대한 기본적인 이해 능력 확인
- **즉시 사용 가능한 기본 성능** 확인

#### 2. **우선 테스트 및 검증**
- 전체 파이프라인 테스트 (전처리 → 학습 → 추론)
- 이상 탐지 로직 검증
- 성능 평가 메트릭 확인
- **프로토타입 개발 및 검증**

#### 3. **합리적인 성능 확보**
- **예상 정확도: 70-75%**
- 완전한 커스텀 학습(85-90%)보다는 낮지만
- 랜덤(50%)보다는 훨씬 높음
- **기본적인 이상 탐지는 가능**

#### 4. **M4 Pro 환경에서 실행**
- CPU만으로도 학습 가능
- 학습 시간: 2-4시간
- 메모리: 4-8GB
- **추가 비용 없음**

### ❌ 불가능한 것

#### 1. **프로덕션 수준 성능**
- 85%+ 정확도는 어려움
- 완전한 커스텀 학습이 필요

#### 2. **복잡한 패턴 학습**
- 로그 특화된 매우 복잡한 패턴은 제한적
- Pre-trained 모델의 한계

## 전이 학습의 작동 원리

### Pre-trained BERT의 장점

```
Pre-trained BERT가 이미 학습한 것:
- 단어/토큰 간의 관계
- 문맥 이해 능력
- 시퀀스 패턴 인식
- 일반적인 언어 구조

우리가 추가로 학습하는 것:
- 로그 특화 패턴
- Event ID 간의 관계
- 로그 시퀀스의 특수한 패턴
```

### 학습 과정

1. **Pre-trained 가중치 로드**
   - BERT가 이미 학습한 일반적인 패턴 활용
   - 처음부터 학습하는 것보다 훨씬 빠름

2. **로그 데이터로 파인튜닝**
   - 로그 특화 패턴 학습
   - 기존 지식 + 새로운 패턴

3. **결과**
   - 일반 언어 이해 + 로그 특화 이해
   - 합리적인 성능 확보

## 예상 성능 비교

### 시나리오별 성능

| 방법 | 정확도 | 학습 시간 | 비용 | 환경 |
|------|--------|----------|------|------|
| **전이 학습** | **70-75%** | 2-4시간 | $0 | M4 Pro |
| 테스트 모델 | 50-60% | 1-2시간 | $0 | M4 Pro |
| 완전 학습 (GPU) | 85-90% | 10-20시간 | $30-60 | 클라우드 |
| 완전 학습 (DGX) | 90%+ | 5-10시간 | $0 | DGX |

### 성능 해석

**70-75% 정확도는:**
- ✅ 랜덤(50%)보다 **40-50% 개선**
- ✅ 기본적인 이상 탐지 **가능**
- ✅ 프로토타입 및 검증용으로 **충분**
- ⚠️ 프로덕션은 **부족** (85%+ 필요)

## 실제 사용 시나리오

### 시나리오 1: 프로토타입 검증

```
목적: 전체 시스템이 동작하는지 확인
방법: 전이 학습 모델 사용
결과: 
  - 파이프라인 검증 ✅
  - 기본 성능 확인 ✅
  - UI/UX 테스트 ✅
  - 성능: 70-75% (검증용으로 충분)
```

### 시나리오 2: 개념 증명 (PoC)

```
목적: 기술적 타당성 입증
방법: 전이 학습 모델 사용
결과:
  - 이상 탐지 가능성 입증 ✅
  - 논문/발표용 데모 ✅
  - 추가 개발 근거 확보 ✅
  - 성능: 70-75% (PoC용으로 충분)
```

### 시나리오 3: 개발/테스트 환경

```
목적: 개발 중 테스트
방법: 전이 학습 모델 사용
결과:
  - 개발 중 빠른 피드백 ✅
  - 코드 검증 ✅
  - 성능: 70-75% (개발용으로 충분)
```

### 시나리오 4: 프로덕션 (부적합)

```
목적: 실제 운영 환경
방법: 전이 학습 모델 사용
결과:
  - 오탐률 높음 ❌
  - 중요한 장애 놓칠 수 있음 ❌
  - 성능: 70-75% (프로덕션용으로 부족)
  - 권장: 완전 학습 모델 필요 (85%+)
```

## 전이 학습 실행 방법

### 기본 실행

```bash
cd logbert_training
python train_transfer.py
```

### 옵션 조정

```bash
# 더 작은 모델 사용 (더 빠름)
python train_transfer.py --pretrained distilbert-base-uncased

# 더 많은 데이터 사용 (더 좋은 성능)
python train_transfer.py --sample-ratio 0.1 --max-files 20
```

## 성능 평가 방법

### 1. Loss 확인

```bash
# 학습 중 Loss 감소 확인
# 정상: Loss가 점진적으로 감소
# 이상: Loss가 수렴하지 않거나 증가
```

### 2. 추론 테스트

```bash
python inference.py \
  --checkpoint checkpoints_transfer/checkpoints/best_model.pt \
  --input ../preprocessing/output/preprocessed_logs_2025-02-24.json \
  --output test_results.json \
  --threshold 2.0
```

### 3. 이상 점수 분포 확인

```python
import json
import numpy as np

with open('test_results.json', 'r') as f:
    results = json.load(f)

scores = [r['anomaly_score'] for r in results]
print(f"평균: {np.mean(scores):.4f}")
print(f"표준편차: {np.std(scores):.4f}")
print(f"최소: {np.min(scores):.4f}")
print(f"최대: {np.max(scores):.4f}")
```

## 전이 학습의 한계와 극복

### 한계

1. **성능 상한선**
   - Pre-trained 모델의 구조 제약
   - 로그 특화 최적화 제한적

2. **데이터 불일치**
   - BERT는 일반 텍스트로 학습
   - 로그는 특수한 형식

### 극복 방법

1. **더 많은 파인튜닝**
   - 에폭 수 증가 (3 → 5-10)
   - 더 많은 데이터 사용

2. **하이퍼파라미터 조정**
   - 학습률 조정
   - 배치 크기 조정

3. **전용 모델로 전환**
   - 전이 학습으로 검증 후
   - 클라우드 GPU로 완전 학습

## 결론

### 전이 학습으로 가능한 것

✅ **Pre-trained 성능 확인**
- BERT의 기본 능력 활용
- 즉시 사용 가능한 성능

✅ **우선 테스트 및 검증**
- 전체 파이프라인 테스트
- 프로토타입 개발
- 개념 증명

✅ **합리적인 성능**
- 70-75% 정확도
- 기본적인 이상 탐지 가능
- 개발/테스트 환경용으로 충분

### 전이 학습으로 불가능한 것

❌ **프로덕션 수준 성능**
- 85%+ 정확도는 어려움
- 완전한 커스텀 학습 필요

## 권장 워크플로우

```
1단계: 전이 학습 (M4 Pro)
  → 파이프라인 검증 ✅
  → 기본 성능 확인 ✅
  → 프로토타입 개발 ✅
  → 시간: 2-4시간, 비용: $0

2단계: 완전 학습 (클라우드 GPU)
  → 프로덕션 수준 성능 확보 ✅
  → 시간: 10-20시간, 비용: $30-60

3단계: 최종 학습 (DGX Station)
  → 최고 성능 확보 ✅
  → 시간: 5-10시간, 비용: $0
```

**요약: 전이 학습으로 Pre-trained 성능 확인 및 우선 테스트가 가능하며, 프로토타입 개발과 개념 증명에는 충분합니다. 다만 프로덕션 배포를 위해서는 완전 학습이 필요합니다.**


