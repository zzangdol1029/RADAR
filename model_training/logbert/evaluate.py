#!/usr/bin/env python3
"""
LogBERT ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨, F1-Score ê³„ì‚°

ì‚¬ìš©ë²•:
python evaluate.py \
    --checkpoint checkpoints_test/checkpoints/best_model.pt \
    --config configs/test_quick.yaml \
    --validation-data /home/zzangdol/RADAR/preprocessing/output/preprocessed_logs_2025-02-24.json \
    --normal-ratio 0.8
"""

import os
import sys
import json
import yaml
import torch
import logging
import numpy as np
from tqdm import tqdm
from pathlib import Path
from typing import Dict, Any, List, Tuple
from datetime import datetime
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_auc_score, roc_curve
)
import matplotlib.pyplot as plt
import seaborn as sns

import platform

# í•œê¸€ í°íŠ¸ ì„¤ì • (Windows ê¸°ì¤€)
if platform.system() == 'Windows':
    plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

# ë¡œì»¬ ëª¨ë“ˆ import
from model import create_logbert_model
from dataset import LogBERTDataset

logger = logging.getLogger(__name__)


def setup_logging(log_file: Path = None):
    """ë¡œê¹… ì„¤ì • - UTF-8 ì¸ì½”ë”© ì§€ì›"""
    log_format = '%(asctime)s - %(levelname)s - %(message)s'
    
    if sys.platform == 'win32':
        import io
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
    
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)
    
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)
    
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(logging.Formatter(log_format))
    
    root_logger.addHandler(console_handler)
    
    if log_file:
        log_file.parent.mkdir(parents=True, exist_ok=True)
        file_handler = logging.FileHandler(log_file, mode='w', encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        file_handler.setFormatter(logging.Formatter(log_format))
        root_logger.addHandler(file_handler)
        logger.info(f"ğŸ“ ë¡œê·¸ íŒŒì¼: {log_file}")
    
    return root_logger


def load_config(config_path: str) -> Dict[str, Any]:
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # ìˆ«ì ê°’ ë³€í™˜
    if 'model' in config:
        for key in config['model']:
            if isinstance(config['model'][key], str):
                try:
                    config['model'][key] = int(config['model'][key]) if '.' not in config['model'][key] else float(config['model'][key])
                except ValueError:
                    pass
    
    if 'data' in config:
        if 'max_seq_length' in config['data']:
            config['data']['max_seq_length'] = int(config['data']['max_seq_length'])
    
    return config


def load_model(checkpoint_path: str, config: Dict[str, Any], device: torch.device):
    """í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ"""
    logger.info(f"ëª¨ë¸ ë¡œë”© ì¤‘: {checkpoint_path}")
    
    # ëª¨ë¸ ìƒì„±
    model = create_logbert_model(config['model'])
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    checkpoint = torch.load(checkpoint_path, map_location=device)
    
    # state_dict ë¡œë“œ (strict=Falseë¡œ ì„¤ì •í•˜ì—¬ position_ids ë“± ë¶ˆì¼ì¹˜ í—ˆìš©)
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'], strict=False)
        logger.info(f"ì²´í¬í¬ì¸íŠ¸ ì •ë³´:")
        logger.info(f"  Global Step: {checkpoint.get('global_step', 'N/A')}")
        logger.info(f"  Best Loss: {checkpoint.get('best_loss', 'N/A'):.4f}")
    else:
        model.load_state_dict(checkpoint, strict=False)
    
    model.to(device)
    model.eval()
    
    logger.info("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    return model


def calculate_anomaly_scores(
    model: torch.nn.Module,
    sessions: List[Dict],
    device: torch.device,
    max_seq_length: int,
    vocab_size: int,
    batch_size: int = 32
) -> List[float]:
    model.eval()
    anomaly_scores = []
    
    # ê°œë³„ í† í°ë³„ ì†ì‹¤ì„ êµ¬í•˜ê¸° ìœ„í•œ í•¨ìˆ˜ (í‰ê· ë‚´ì§€ ì•ŠìŒ)
    # 0ë²ˆ(PAD)ì€ ê³„ì‚°ì—ì„œ ì œì™¸(ignore_index=0)
    criterion = torch.nn.CrossEntropyLoss(reduction='none', ignore_index=0)

    for i in tqdm(range(0, len(sessions), batch_size), desc="ì ìˆ˜ ê³„ì‚° ì¤‘"):
        batch_sessions = sessions[i : i + batch_size]
        
        batch_input_ids = []
        for s in batch_sessions:
            tokens = s.get('token_ids', [])[:max_seq_length]
            tokens += [0] * (max_seq_length - len(tokens)) 
            batch_input_ids.append(tokens)
            
        input_ids = torch.tensor(batch_input_ids, dtype=torch.long).to(device)
        attention_mask = (input_ids != 0).long().to(device)
        labels = input_ids.clone()

        with torch.no_grad():
            # ëª¨ë¸ë¡œë¶€í„° ë¡œì§“(Logits)ì„ ì§ì ‘ ê°€ì ¸ì˜´
            outputs = model(input_ids=input_ids, attention_mask=attention_mask)
            logits = outputs['logits'] # [Batch, Seq, Vocab]

            # CrossEntropy ê³„ì‚°ì„ ìœ„í•´ ì°¨ì› ë³€ê²½
            # logits: [Batch * Seq, Vocab], labels: [Batch * Seq]
            flat_logits = logits.view(-1, vocab_size)
            flat_labels = labels.view(-1)
            
            # 1. ëª¨ë“  í† í°ì˜ ê°œë³„ Loss ê³„ì‚°
            token_losses = criterion(flat_logits, flat_labels) 
            token_losses = token_losses.view(input_ids.size(0), -1) # [Batch, Seq]
            
            # 2. ì„¸ì…˜ë³„ í‰ê·  Loss ê³„ì‚° (íŒ¨ë”© ì œì™¸)
            # ì‹¤ì œ í† í° ê°œìˆ˜ë¡œ ë‚˜ëˆ„ì–´ ì •í™•í•œ ì„¸ì…˜ë³„ ì ìˆ˜ ì‚°ì¶œ
            actual_counts = attention_mask.sum(dim=1)
            session_losses = token_losses.sum(dim=1) / actual_counts
            
            anomaly_scores.extend(session_losses.cpu().numpy().tolist())
                
    return anomaly_scores

def load_validation_data(data_path: str, normal_ratio: float = 0.8, max_samples: int = None) -> Tuple[List[Dict], List[Dict]]:
    data_path = Path(data_path)
    sessions = []
    
    if data_path.is_dir():
        logger.info(f"ğŸ“ ê²€ì¦ ë°ì´í„° ë””ë ‰í† ë¦¬ ë¡œë“œ ì¤‘: {data_path}")
        files = sorted(data_path.glob("preprocessed_logs_*.json"))
        if not files:
            logger.warning(f"âŒ í•´ë‹¹ ë””ë ‰í† ë¦¬ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {data_path}")
            return [], []
            
        logger.info(f"   ë°œê²¬ëœ íŒŒì¼ ìˆ˜: {len(files)}ê°œ")
        
        for file_path in files:
            # ëª©í‘œ ìƒ˜í”Œ ìˆ˜ë¥¼ ì´ë¯¸ ë‹¤ ì±„ì› ë‹¤ë©´ ë” ì´ìƒ íŒŒì¼ì„ ì—´ì§€ ì•ŠìŒ
            if max_samples is not None and len(sessions) >= max_samples:
                break
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    new_sessions = data if isinstance(data, list) else data.get('sessions', [])
                    sessions.extend(new_sessions)
                    # íŒŒì¼ í•˜ë‚˜ ì½ì„ ë•Œë§ˆë‹¤ í˜„ì¬ ìˆ˜ì§‘ í˜„í™© ë¡œê·¸ ì¶œë ¥
                    logger.info(f"   ë¡œë“œ ì¤‘... í˜„ì¬ {len(sessions):,}ê°œ ìˆ˜ì§‘ë¨ ({file_path.name})")
            except Exception as e:
                logger.error(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({file_path.name}): {e}")
                
    elif data_path.is_file():
        # (íŒŒì¼ í•˜ë‚˜ì¼ ë•ŒëŠ” ê¸°ì¡´ê³¼ ë™ì¼)
        logger.info(f"ğŸ“„ ê²€ì¦ ë°ì´í„° íŒŒì¼ ë¡œë“œ ì¤‘: {data_path}")
        with open(data_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            sessions = data if isinstance(data, list) else data.get('sessions', [])
            
    else:
        logger.error(f"âŒ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_path}")
        return [], []

    # ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ max_samplesì— ë§ì¶° ìë¥´ê¸°
    if max_samples is not None and len(sessions) > max_samples:
        import random
        random.seed(42)
        sessions = random.sample(sessions, max_samples)
        logger.info(f"âš¡ ìƒ˜í”Œë§ ì™„ë£Œ: {max_samples}ê°œ ì„ íƒë¨")

    total_sessions = len(sessions)
    if total_sessions == 0:
        return [], []

    # ì •ìƒ/ì´ìƒ ë¶„ë¦¬
    split_idx = int(total_sessions * normal_ratio)
    normal_sessions = sessions[:split_idx]
    anomaly_sessions = sessions[split_idx:]
    
    logger.info(f"ì´ ì„¸ì…˜ ìˆ˜: {total_sessions}")
    logger.info(f"ì •ìƒ ì„¸ì…˜: {len(normal_sessions)} ({len(normal_sessions)/total_sessions*100:.1f}%)")
    logger.info(f"ì´ìƒ ì„¸ì…˜: {len(anomaly_sessions)} ({len(anomaly_sessions)/total_sessions*100:.1f}%)")
    
    return normal_sessions, anomaly_sessions


def generate_pseudo_anomalies(
    sessions: List[Dict],
    vocab_size: int,
    max_seq_len: int,
    ratio: float = 0.1,  # 10% í† í° ë³€ì¡°
    num_anomalies: int = None
) -> List[Dict]:
    """ì •ìƒ ì„¸ì…˜ì„ ë³€ì¡°í•˜ì—¬ ê°€ì§œ ì´ìƒ ë°ì´í„° ìƒì„±"""
    import random
    import copy
    
    if num_anomalies is None:
        num_anomalies = len(sessions)
    
    # ì›ë³¸ ë°ì´í„°ì—ì„œ ìƒ˜í”Œë§ (ë³µì› ì¶”ì¶œ í—ˆìš©)
    sampled_sessions = random.choices(sessions, k=num_anomalies)
    anomaly_sessions = copy.deepcopy(sampled_sessions)
    
    for session in anomaly_sessions:
        tokens = session.get('token_ids', session.get('tokens', []))
        if not tokens:
            continue
            
        # ë³€ì¡°í•  í† í° ê°œìˆ˜
        num_mod = max(1, int(len(tokens) * ratio))
        
        # ëœë¤í•˜ê²Œ ì¸ë±ìŠ¤ ì„ íƒ
        indices = random.sample(range(len(tokens)), min(num_mod, len(tokens)))
        
        for idx in indices:
            # ëœë¤ í† í°ìœ¼ë¡œ êµì²´ (ë‹¨, [PAD], [CLS], [SEP], [MASK] ë“±ì€ í”¼í•˜ëŠ” ê²ƒì´ ì¢‹ì§€ë§Œ ê°„ë‹¨íˆ êµ¬í˜„)
            # ì—¬ê¸°ì„œëŠ” 5ë²ˆë¶€í„° vocab_size-1 ì‚¬ì´ì˜ ëœë¤ ì •ìˆ˜ë¡œ êµì²´ (0~4ëŠ” íŠ¹ìˆ˜ í† í° ê°€ì •)
            tokens[idx] = random.randint(5, vocab_size - 1)
            
        session['label'] = 1  # ì´ìƒ ë ˆì´ë¸”
    
    return anomaly_sessions


def calculate_metrics(
    normal_scores: List[float],
    anomaly_scores: List[float],
    threshold: float
) -> Dict[str, float]:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°"""
    # ë ˆì´ë¸” ìƒì„± (0: ì •ìƒ, 1: ì´ìƒ)
    y_true = [0] * len(normal_scores) + [1] * len(anomaly_scores)
    
    # ì˜ˆì¸¡ ìƒì„± (ì„ê³„ê°’ ê¸°ì¤€)
    y_pred = [int(score >= threshold) for score in normal_scores] + \
             [int(score >= threshold) for score in anomaly_scores]
    
    # ì ìˆ˜ (ROC AUCìš©)
    y_scores = normal_scores + anomaly_scores
    
    # ë©”íŠ¸ë¦­ ê³„ì‚°
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, zero_division=0)
    recall = recall_score(y_true, y_pred, zero_division=0)
    f1 = f1_score(y_true, y_pred, zero_division=0)
    
    try:
        roc_auc = roc_auc_score(y_true, y_scores)
    except ValueError:
        roc_auc = 0.0
    
    # í˜¼ë™ í–‰ë ¬
    cm = confusion_matrix(y_true, y_pred)
    tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0, 0, 0, 0)
    
    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'roc_auc': roc_auc,
        'confusion_matrix': cm,
        'true_negative': int(tn),
        'false_positive': int(fp),
        'false_negative': int(fn),
        'true_positive': int(tp),
        'y_true': y_true,
        'y_pred': y_pred,
        'y_scores': y_scores
    }


def find_optimal_threshold(
    normal_scores: List[float],
    anomaly_scores: List[float],
    num_thresholds: int = 100
) -> Tuple[float, Dict[str, float]]:
    """ìµœì  ì„ê³„ê°’ ì°¾ê¸° (F1-Score ìµœëŒ€í™”)"""
    min_score = min(min(normal_scores), min(anomaly_scores))
    max_score = max(max(normal_scores), max(anomaly_scores))
    
    thresholds = np.linspace(min_score, max_score, num_thresholds)
    best_threshold = None
    best_metrics = None
    best_f1 = 0.0
    
    for threshold in thresholds:
        metrics = calculate_metrics(normal_scores, anomaly_scores, threshold)
        if metrics['f1_score'] > best_f1:
            best_f1 = metrics['f1_score']
            best_threshold = threshold
            best_metrics = metrics
    
    return best_threshold, best_metrics


def plot_score_distribution(
    normal_scores: List[float],
    anomaly_scores: List[float],
    threshold: float,
    output_path: Path
):
    """ì ìˆ˜ ë¶„í¬ ì‹œê°í™”"""
    plt.figure(figsize=(12, 6))
    
    plt.subplot(1, 2, 1)
    plt.hist(normal_scores, bins=50, alpha=0.7, label='ì •ìƒ', color='blue', edgecolor='black')
    plt.hist(anomaly_scores, bins=50, alpha=0.7, label='ì´ìƒ', color='red', edgecolor='black')
    plt.axvline(threshold, color='green', linestyle='--', linewidth=2, label=f'ì„ê³„ê°’: {threshold:.4f}')
    plt.xlabel('ì´ìƒ ì ìˆ˜ (Loss)')
    plt.ylabel('ë¹ˆë„')
    plt.title('ì •ìƒ vs ì´ìƒ ì ìˆ˜ ë¶„í¬')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.subplot(1, 2, 2)
    plt.boxplot([normal_scores, anomaly_scores], tick_labels=['ì •ìƒ', 'ì´ìƒ'])
    plt.axhline(threshold, color='green', linestyle='--', linewidth=2, label=f'ì„ê³„ê°’: {threshold:.4f}')
    plt.ylabel('ì´ìƒ ì ìˆ˜ (Loss)')
    plt.title('ì •ìƒ vs ì´ìƒ ì ìˆ˜ ë°•ìŠ¤í”Œë¡¯')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    logger.info(f"ğŸ“Š ì ìˆ˜ ë¶„í¬ ê·¸ë˜í”„ ì €ì¥: {output_path}")
    plt.close()

def plot_confusion_matrix(cm: np.ndarray, output_path: Path):
    """í˜¼ë™ í–‰ë ¬ ì‹œê°í™”"""
    plt.figure(figsize=(8, 6))
    sns.heatmap(
        cm,
        annot=True,
        fmt='d',
        cmap='Blues',
        xticklabels=['ì •ìƒ', 'ì´ìƒ'],
        yticklabels=['ì •ìƒ', 'ì´ìƒ'],
        cbar_kws={'label': 'ê°œìˆ˜'}
    )
    plt.xlabel('ì˜ˆì¸¡')
    plt.ylabel('ì‹¤ì œ')
    plt.title('í˜¼ë™ í–‰ë ¬ (Confusion Matrix)')
    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    logger.info(f"ğŸ“Š í˜¼ë™ í–‰ë ¬ ì €ì¥: {output_path}")
    plt.close()


def save_evaluation_results(
    results: Dict[str, Any],
    output_path: Path
):
    """í‰ê°€ ê²°ê³¼ ì €ì¥"""
    # NumPy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    serializable_results = {}
    for key, value in results.items():
        if isinstance(value, np.ndarray):
            serializable_results[key] = value.tolist()
        elif isinstance(value, (np.integer, np.floating)):
            serializable_results[key] = float(value)
        else:
            serializable_results[key] = value
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(serializable_results, f, indent=2, ensure_ascii=False)
    
    logger.info(f"ğŸ’¾ í‰ê°€ ê²°ê³¼ ì €ì¥: {output_path}")


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='LogBERT ëª¨ë¸ ì„±ëŠ¥ í‰ê°€')
    parser.add_argument('--checkpoint', type=str, required=True,
                        help='ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ')
    parser.add_argument('--config', type=str, required=True,
                        help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--validation-data', type=str, required=True,
                        help='ê²€ì¦ ë°ì´í„° íŒŒì¼ ê²½ë¡œ ë˜ëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    parser.add_argument('--normal-ratio', type=float, default=0.8,
                        help='ì •ìƒ ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.8)')
    parser.add_argument('--max-samples', type=int, default=None,
                        help='ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ (ë¹ ë¥¸ í‰ê°€ìš©, ì˜ˆ: 1000)')
    parser.add_argument('--output-dir', type=str, default='evaluation_results',
                        help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--log-file', type=str, default=None,
                        help='ë¡œê·¸ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--generate-fake-anomaly', action='store_true',
                        help='ê°€ì§œ ì´ìƒ ë°ì´í„° ìƒì„±í•˜ì—¬ í‰ê°€ (ì´ìƒ ë°ì´í„°ê°€ ì—†ì„ ë•Œ ìœ ìš©)')
    parser.add_argument('--anomaly-ratio', type=float, default=0.1,
                        help='ê°€ì§œ ì´ìƒ ë°ì´í„° ìƒì„± ì‹œ í† í° ë³€ì¡° ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.1)')
    parser.add_argument('--batch-size', type=int, default=32,
                        help='í‰ê°€ ì‹œ ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 32)')
    
    args = parser.parse_args()
    
    # 1. ì²´í¬í¬ì¸íŠ¸ ì´ë¦„ ì¶”ì¶œ ë° ì¶œë ¥ ê²½ë¡œ ì„¤ì • (ratio í¬í•¨)
    checkpoint_path = Path(args.checkpoint)
    checkpoint_name = checkpoint_path.stem 
    output_dir = Path(args.output_dir) / f"{checkpoint_name}_ratio_{args.anomaly_ratio}"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # 2. ë¡œê·¸ íŒŒì¼ ì„¤ì •
    if args.log_file:
        log_file = Path(args.log_file)
    else:
        logs_dir = Path(__file__).parent / 'logs'
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        log_file = logs_dir / f'evaluation_{checkpoint_name}_{timestamp}.log'
    
    setup_logging(log_file)
    
    logger.info("=" * 80)
    logger.info(f"LogBERT ëª¨ë¸ ì„±ëŠ¥ í‰ê°€: {checkpoint_name}")
    logger.info(f"ë³€ì¡° ë¹„ìœ¨: {args.anomaly_ratio}")
    logger.info(f"ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_dir}")
    logger.info("=" * 80)
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger.info(f"ë””ë°”ì´ìŠ¤: {device}")
    
    # ì„¤ì • ë° ëª¨ë¸ ë¡œë“œ
    config = load_config(args.config)
    model = load_model(args.checkpoint, config, device)
    
    # ê²€ì¦ ë°ì´í„° ë¡œë“œ
    normal_sessions, anomaly_sessions = load_validation_data(
        args.validation_data,
        args.normal_ratio,
        args.max_samples
    )

    if not normal_sessions and not anomaly_sessions:
        logger.error("âŒ ê²€ì¦ìš© ì„¸ì…˜ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    # 3. ê°€ì§œ ì´ìƒ ë°ì´í„° ìƒì„± (ì˜µì…˜)
    if args.generate_fake_anomaly:
        logger.info("\n" + "=" * 80)
        logger.info("âš ï¸  ê°€ì§œ ì´ìƒ ë°ì´í„°(Pseudo-Anomaly) ìƒì„± ëª¨ë“œ")
        logger.info("=" * 80)
        
        all_normal = normal_sessions + anomaly_sessions
        normal_sessions = all_normal # ë³€ì¡°ë˜ì§€ ì•Šì€ ì›ë³¸ì„ ëª¨ë‘ ì •ìƒêµ°ìœ¼ë¡œ ì„¤ì •
        
        # ì‚¬ìš©ìê°€ ì…ë ¥í•œ anomaly-ratioë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ìƒ ë°ì´í„° ìƒì„±
        anomaly_sessions = generate_pseudo_anomalies(
            all_normal,
            vocab_size=config['model']['vocab_size'],
            max_seq_len=config['data']['max_seq_length'],
            ratio=args.anomaly_ratio
        )
        logger.info(f"âœ… ë°ì´í„° ì¬êµ¬ì„± ì™„ë£Œ: {len(normal_sessions)}ê°œ ì •ìƒ / {len(anomaly_sessions)}ê°œ ì´ìƒ")

    # 4. ì´ìƒ ì ìˆ˜ ê³„ì‚°
    logger.info("\n" + "=" * 80)
    logger.info("ì´ìƒ ì ìˆ˜ ê³„ì‚° ì¤‘...")
    logger.info("=" * 80)
    
    max_seq_length = config['data']['max_seq_length']
    vocab_size = config['model']['vocab_size']
    
    logger.info("ì •ìƒ ì„¸ì…˜ í‰ê°€ ì¤‘...")
    normal_scores = calculate_anomaly_scores(
        model, normal_sessions, device, max_seq_length, vocab_size, batch_size=args.batch_size
    )
    
    logger.info("ì´ìƒ ì„¸ì…˜ í‰ê°€ ì¤‘...")
    anomaly_scores = calculate_anomaly_scores(
        model, anomaly_sessions, device, max_seq_length, vocab_size, batch_size=args.batch_size
    )
    
    logger.info(f"âœ… ì •ìƒ ì„¸ì…˜ ì ìˆ˜ ê³„ì‚° ì™„ë£Œ: {len(normal_scores)}ê°œ")
    logger.info(f"âœ… ì´ìƒ ì„¸ì…˜ ì ìˆ˜ ê³„ì‚° ì™„ë£Œ: {len(anomaly_scores)}ê°œ")
    
    # ì ìˆ˜ í†µê³„
    logger.info("\n" + "=" * 80)
    logger.info("ì ìˆ˜ í†µê³„")
    logger.info("=" * 80)
    logger.info(f"ì •ìƒ ì„¸ì…˜ - í‰ê· : {np.mean(normal_scores):.4f}, í‘œì¤€í¸ì°¨: {np.std(normal_scores):.4f}")
    logger.info(f"ì´ìƒ ì„¸ì…˜ - í‰ê· : {np.mean(anomaly_scores):.4f}, í‘œì¤€í¸ì°¨: {np.std(anomaly_scores):.4f}")
    
    # ìµœì  ì„ê³„ê°’ ì°¾ê¸° ë° ë©”íŠ¸ë¦­ ê³„ì‚°
    logger.info("\n" + "=" * 80)
    logger.info("ìµœì  ì„ê³„ê°’ íƒìƒ‰ ë° ê²°ê³¼ ì‚°ì¶œ")
    logger.info("=" * 80)
    
    best_threshold, best_metrics = find_optimal_threshold(normal_scores, anomaly_scores)
    
    logger.info(f"âœ… ìµœì  ì„ê³„ê°’: {best_threshold:.4f}")
    
    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶œë ¥
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“Š ì„±ëŠ¥ í‰ê°€ ê²°ê³¼")
    logger.info("=" * 80)
    logger.info(f"ì •í™•ë„ (Accuracy):  {best_metrics['accuracy']:.4f} ({best_metrics['accuracy']*100:.2f}%)")
    logger.info(f"ì •ë°€ë„ (Precision): {best_metrics['precision']:.4f} ({best_metrics['precision']*100:.2f}%)")
    logger.info(f"ì¬í˜„ìœ¨ (Recall):    {best_metrics['recall']:.4f} ({best_metrics['recall']*100:.2f}%)")
    logger.info(f"F1-Score:          {best_metrics['f1_score']:.4f} ({best_metrics['f1_score']*100:.2f}%)")
    logger.info(f"ROC AUC:           {best_metrics['roc_auc']:.4f}")
    
    logger.info("\ní˜¼ë™ í–‰ë ¬:")
    logger.info(f"  True Negative (TN):  {best_metrics['true_negative']:4d} (ì •ìƒì„ ì •ìƒìœ¼ë¡œ ì˜ˆì¸¡)")
    logger.info(f"  False Positive (FP): {best_metrics['false_positive']:4d} (ì •ìƒì„ ì´ìƒìœ¼ë¡œ ì˜ˆì¸¡)")
    logger.info(f"  False Negative (FN): {best_metrics['false_negative']:4d} (ì´ìƒì„ ì •ìƒìœ¼ë¡œ ì˜ˆì¸¡)")
    logger.info(f"  True Positive (TP):  {best_metrics['true_positive']:4d} (ì´ìƒì„ ì´ìƒìœ¼ë¡œ ì˜ˆì¸¡)")
    
    # 5. ì‹œê°í™” ë° ê²°ê³¼ ì €ì¥
    plot_score_distribution(
        normal_scores, anomaly_scores, best_threshold,
        output_dir / f'score_dist_{checkpoint_name}.png'
    )
    
    plot_confusion_matrix(
        best_metrics['confusion_matrix'],
        output_dir / f'confusion_matrix_{checkpoint_name}.png'
    )
    
    # ê²°ê³¼ JSON ì €ì¥ìš© ë°ì´í„° êµ¬ì„±
    results = {
        'checkpoint': args.checkpoint,
        'anomaly_ratio': args.anomaly_ratio,
        'optimal_threshold': float(best_threshold),
        'metrics': {
            'accuracy': float(best_metrics['accuracy']),
            'precision': float(best_metrics['precision']),
            'recall': float(best_metrics['recall']),
            'f1_score': float(best_metrics['f1_score']),
            'roc_auc': float(best_metrics['roc_auc']),
        },
        'confusion_matrix': {
            'true_negative': int(best_metrics['true_negative']),
            'false_positive': int(best_metrics['false_positive']),
            'false_negative': int(best_metrics['false_negative']),
            'true_positive': int(best_metrics['true_positive']),
        },
        'statistics': {
            'normal_mean': float(np.mean(normal_scores)),
            'normal_std': float(np.std(normal_scores)),
            'normal_min': float(np.min(normal_scores)),
            'normal_max': float(np.max(normal_scores)),
            'anomaly_mean': float(np.mean(anomaly_scores)),
            'anomaly_std': float(np.std(anomaly_scores)),
            'anomaly_min': float(np.min(anomaly_scores)),
            'anomaly_max': float(np.max(anomaly_scores)),
        }
    }
    
    save_evaluation_results(results, output_dir / f'evaluation_results_{checkpoint_name}.json')
    
    logger.info("\n" + "=" * 80)
    logger.info(f"âœ… í‰ê°€ ì™„ë£Œ! ê²°ê³¼ ì €ì¥: {output_dir}")
    logger.info("=" * 80)


if __name__ == '__main__':
    main()
