# ì „ì²˜ë¦¬ ë°ì´í„° ê³µìœ  í”„ë¡œí† ì½œ

## ğŸ“‹ ê°œìš”

ë©¤ë²„ 1ì´ ìƒì„±í•œ ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ë‹¤ë¥¸ ë©¤ë²„ë“¤ì´ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ê³µìœ í•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.

---

## ğŸ“ ë°ì´í„° ì €ì¥ ìœ„ì¹˜

### ê³µìœ  ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
preprocessing/output/
â”œâ”€â”€ preprocessed_logs_2025-02-24.json
â”œâ”€â”€ preprocessed_logs_2025-02-25.json
â”œâ”€â”€ preprocessed_logs_2025-02-26.json
â””â”€â”€ ...
```

### ë©”íƒ€ë°ì´í„° íŒŒì¼

```
preprocessing/output/
â”œâ”€â”€ metadata.json          # ë°ì´í„° ë©”íƒ€ë°ì´í„°
â”œâ”€â”€ data_schema.json       # ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì •ì˜
â””â”€â”€ README.md              # ì‚¬ìš© ê°€ì´ë“œ
```

---

## ğŸ“Š ë°ì´í„° í˜•ì‹

### ì„¸ì…˜ ë°ì´í„° êµ¬ì¡°

```json
{
  "session_id": 0,
  "event_sequence": [1, 5, 1, 12, 3],
  "token_ids": [101, 1, 2, 1, 3, 4, 102, 0, 0, ...],
  "attention_mask": [1, 1, 1, 1, 1, 1, 1, 0, 0, ...],
  "has_error": false,
  "has_warn": true,
  "service_name": "gateway",
  "trace_id": "abc123",
  "original_logs": [
    "2025-12-08 17:23:47.950 INFO ...",
    "2025-12-08 17:23:48.123 WARN ..."
  ],
  "simplified_text": "[gateway] INFO [main] Starting Application | WARN ...",
  "timestamp": "2025-12-08T17:23:47",
  "session_length": 25
}
```

### í•„ìˆ˜ í•„ë“œ

- `session_id`: ì„¸ì…˜ ê³ ìœ  ID
- `token_ids`: í† í° ID ì‹œí€€ìŠ¤ (List[int])
- `attention_mask`: ì–´í…ì…˜ ë§ˆìŠ¤í¬ (List[int])
- `service_name`: ì„œë¹„ìŠ¤ëª… (str)

### ì„ íƒ í•„ë“œ

- `event_sequence`: ì´ë²¤íŠ¸ ID ì‹œí€€ìŠ¤
- `has_error`: ì—ëŸ¬ í¬í•¨ ì—¬ë¶€
- `has_warn`: ê²½ê³  í¬í•¨ ì—¬ë¶€
- `trace_id`: Trace ID
- `original_logs`: ì›ë³¸ ë¡œê·¸ ë¦¬ìŠ¤íŠ¸
- `simplified_text`: ê°„ì†Œí™”ëœ í…ìŠ¤íŠ¸
- `timestamp`: íƒ€ì„ìŠ¤íƒ¬í”„

---

## ğŸ”„ ë°ì´í„° ê³µìœ  ë°©ë²•

### ë°©ë²• 1: ê³µìœ  ë””ë ‰í† ë¦¬ (ì„œë²„ í™˜ê²½)

**ë©¤ë²„ 1:**
```bash
# ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ê³µìœ  ë””ë ‰í† ë¦¬ì— ì €ì¥
preprocessing/output/  # ëª¨ë“  ë©¤ë²„ê°€ ì ‘ê·¼ ê°€ëŠ¥
```

**ë‹¤ë¥¸ ë©¤ë²„ë“¤:**
```bash
# ë™ì¼í•œ ë°ì´í„° ë””ë ‰í† ë¦¬ ì‚¬ìš©
python train_logbert.py --data-dir ../preprocessing/output
```

---

### ë°©ë²• 2: Git LFS (ëŒ€ìš©ëŸ‰ íŒŒì¼)

**ì„¤ì •:**
```bash
# Git LFS ì„¤ì¹˜ ë° ì„¤ì •
git lfs install
git lfs track "preprocessing/output/*.json"

# ì „ì²˜ë¦¬ëœ ë°ì´í„° ì»¤ë°‹
git add preprocessing/output/
git commit -m "ì „ì²˜ë¦¬ëœ ë°ì´í„° ì¶”ê°€"
git push
```

**ë‹¤ë¥¸ ë©¤ë²„ë“¤:**
```bash
# Git LFS íŒŒì¼ ë‹¤ìš´ë¡œë“œ
git lfs pull
```

---

### ë°©ë²• 3: ì••ì¶• íŒŒì¼ ê³µìœ 

**ë©¤ë²„ 1:**
```bash
# ì „ì²˜ë¦¬ëœ ë°ì´í„° ì••ì¶•
tar -czf preprocessed_data.tar.gz preprocessing/output/

# ë˜ëŠ” ZIP í˜•ì‹
zip -r preprocessed_data.zip preprocessing/output/
```

**ë‹¤ë¥¸ ë©¤ë²„ë“¤:**
```bash
# ì••ì¶• í•´ì œ
tar -xzf preprocessed_data.tar.gz
# ë˜ëŠ”
unzip preprocessed_data.zip
```

---

### ë°©ë²• 4: í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€

**ë©¤ë²„ 1:**
```bash
# AWS S3, Google Cloud Storage ë“±ì— ì—…ë¡œë“œ
aws s3 cp preprocessing/output/ s3://bucket/preprocessed_data/ --recursive
```

**ë‹¤ë¥¸ ë©¤ë²„ë“¤:**
```bash
# ë‹¤ìš´ë¡œë“œ
aws s3 cp s3://bucket/preprocessed_data/ preprocessing/output/ --recursive
```

---

## ğŸ“ ë©”íƒ€ë°ì´í„° íŒŒì¼

### `metadata.json`

```json
{
  "version": "1.0",
  "created_at": "2026-01-10T10:00:00",
  "created_by": "member1",
  "total_sessions": 2464136,
  "date_range": {
    "start": "2025-02-24",
    "end": "2025-12-08"
  },
  "services": ["gateway", "eureka", "research", "manager", "code"],
  "data_files": [
    "preprocessed_logs_2025-02-24.json",
    "preprocessed_logs_2025-02-25.json",
    ...
  ],
  "statistics": {
    "total_sessions": 2464136,
    "sessions_with_errors": 123456,
    "sessions_with_warnings": 234567,
    "sessions_with_trace_id": 2000000
  },
  "preprocessing_config": {
    "window_size": 20,
    "max_seq_length": 512,
    "vocab_size": 10000
  }
}
```

### `data_schema.json`

```json
{
  "session_schema": {
    "session_id": {
      "type": "integer",
      "required": true,
      "description": "ì„¸ì…˜ ê³ ìœ  ID"
    },
    "token_ids": {
      "type": "array",
      "items": {"type": "integer"},
      "required": true,
      "description": "í† í° ID ì‹œí€€ìŠ¤",
      "max_length": 512
    },
    "attention_mask": {
      "type": "array",
      "items": {"type": "integer"},
      "required": true,
      "description": "ì–´í…ì…˜ ë§ˆìŠ¤í¬",
      "max_length": 512
    },
    "service_name": {
      "type": "string",
      "required": true,
      "description": "ì„œë¹„ìŠ¤ëª…",
      "enum": ["gateway", "eureka", "research", "manager", "code"]
    },
    "trace_id": {
      "type": "string",
      "required": false,
      "description": "Trace ID"
    }
  }
}
```

---

## âœ… ë°ì´í„° ê²€ì¦

### ë©¤ë²„ 1ì´ ìˆ˜í–‰í•  ê²€ì¦

```python
def validate_preprocessed_data(data_dir: Path):
    """ì „ì²˜ë¦¬ëœ ë°ì´í„° ê²€ì¦"""
    issues = []
    
    for json_file in data_dir.glob('preprocessed_*.json'):
        with open(json_file, 'r', encoding='utf-8') as f:
            sessions = json.load(f)
        
        for i, session in enumerate(sessions):
            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            if 'token_ids' not in session:
                issues.append(f"{json_file.name}:{i} - token_ids ì—†ìŒ")
            if 'attention_mask' not in session:
                issues.append(f"{json_file.name}:{i} - attention_mask ì—†ìŒ")
            
            # ê¸¸ì´ ì¼ì¹˜ í™•ì¸
            if len(session['token_ids']) != len(session['attention_mask']):
                issues.append(f"{json_file.name}:{i} - ê¸¸ì´ ë¶ˆì¼ì¹˜")
            
            # ìµœëŒ€ ê¸¸ì´ í™•ì¸
            if len(session['token_ids']) > 512:
                issues.append(f"{json_file.name}:{i} - ê¸¸ì´ ì´ˆê³¼")
    
    if issues:
        print(f"ê²½ê³ : {len(issues)}ê°œ ë¬¸ì œ ë°œê²¬")
        for issue in issues[:10]:  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
            print(f"  - {issue}")
    else:
        print("âœ… ë°ì´í„° ê²€ì¦ í†µê³¼")
    
    return len(issues) == 0
```

---

## ğŸ“– ì‚¬ìš© ê°€ì´ë“œ (ë‹¤ë¥¸ ë©¤ë²„ë“¤ì„ ìœ„í•œ)

### ë°ì´í„° ë¡œë“œ ì˜ˆì‹œ

```python
import json
from pathlib import Path
from typing import List, Dict, Any

def load_preprocessed_data(data_dir: Path) -> List[Dict[str, Any]]:
    """ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ"""
    all_sessions = []
    
    # ë©”íƒ€ë°ì´í„° í™•ì¸
    metadata_path = data_dir / 'metadata.json'
    if metadata_path.exists():
        with open(metadata_path, 'r') as f:
            metadata = json.load(f)
            print(f"ë°ì´í„° ë²„ì „: {metadata['version']}")
            print(f"ì´ ì„¸ì…˜ ìˆ˜: {metadata['total_sessions']:,}")
    
    # ë°ì´í„° íŒŒì¼ ë¡œë“œ
    json_files = sorted(data_dir.glob('preprocessed_*.json'))
    print(f"ë°œê²¬ëœ ë°ì´í„° íŒŒì¼: {len(json_files)}ê°œ")
    
    for json_file in json_files:
        with open(json_file, 'r', encoding='utf-8') as f:
            sessions = json.load(f)
            all_sessions.extend(sessions)
            print(f"  - {json_file.name}: {len(sessions):,}ê°œ ì„¸ì…˜")
    
    print(f"ì´ ë¡œë“œëœ ì„¸ì…˜: {len(all_sessions):,}ê°œ")
    return all_sessions

# ì‚¬ìš© ì˜ˆì‹œ
data_dir = Path('../preprocessing/output')
sessions = load_preprocessed_data(data_dir)
```

---

## ğŸ” ë°ì´í„° í’ˆì§ˆ í™•ì¸

### í†µê³„ ì •ë³´ ì¶œë ¥

```python
def print_data_statistics(sessions: List[Dict[str, Any]]):
    """ë°ì´í„° í†µê³„ ì¶œë ¥"""
    total = len(sessions)
    
    # ì„œë¹„ìŠ¤ë³„ í†µê³„
    service_counts = {}
    error_counts = {}
    trace_id_counts = {}
    
    for session in sessions:
        service = session.get('service_name', 'unknown')
        service_counts[service] = service_counts.get(service, 0) + 1
        
        if session.get('has_error', False):
            error_counts[service] = error_counts.get(service, 0) + 1
        
        if session.get('trace_id'):
            trace_id_counts[service] = trace_id_counts.get(service, 0) + 1
    
    print("=" * 80)
    print("ë°ì´í„° í†µê³„")
    print("=" * 80)
    print(f"ì´ ì„¸ì…˜ ìˆ˜: {total:,}")
    print(f"\nì„œë¹„ìŠ¤ë³„ ì„¸ì…˜ ìˆ˜:")
    for service, count in sorted(service_counts.items()):
        error_rate = error_counts.get(service, 0) / count * 100
        trace_rate = trace_id_counts.get(service, 0) / count * 100
        print(f"  {service}: {count:,}ê°œ (ì—ëŸ¬: {error_rate:.1f}%, Trace ID: {trace_rate:.1f}%)")
```

---

## ğŸ“… ë°ì´í„° ê³µìœ  ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë©¤ë²„ 1 (ì „ì²˜ë¦¬ ë‹´ë‹¹)

- [ ] ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì™„ì„±
- [ ] ì „ì²˜ë¦¬ëœ ë°ì´í„° ìƒì„±
- [ ] ë°ì´í„° ê²€ì¦ ìˆ˜í–‰
- [ ] ë©”íƒ€ë°ì´í„° íŒŒì¼ ìƒì„± (`metadata.json`)
- [ ] ë°ì´í„° ìŠ¤í‚¤ë§ˆ ë¬¸ì„œí™” (`data_schema.json`)
- [ ] README ì‘ì„± (`README.md`)
- [ ] ë°ì´í„° ê³µìœ  (ê³µìœ  ë””ë ‰í† ë¦¬/Git/ì••ì¶• íŒŒì¼)
- [ ] ë‹¤ë¥¸ ë©¤ë²„ë“¤ì—ê²Œ ê³µìœ  ì™„ë£Œ ì•Œë¦¼

### ë©¤ë²„ 2, 3, 4 (ëª¨ë¸ í•™ìŠµ ë‹´ë‹¹)

- [ ] ì „ì²˜ë¦¬ëœ ë°ì´í„° í™•ì¸
- [ ] ë°ì´í„° í˜•ì‹ ê²€ì¦
- [ ] ë°ì´í„° ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
- [ ] ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„
- [ ] í•™ìŠµ ì‹œì‘

---

## ğŸ’¡ íŒ

### 1. ë°ì´í„° í¬ê¸° ê´€ë¦¬

```python
# ëŒ€ìš©ëŸ‰ ë°ì´í„°ëŠ” ë‚ ì§œë³„ë¡œ ë¶„í• 
# ê° íŒŒì¼ì´ 100MB ì´í•˜ê°€ ë˜ë„ë¡ ì¡°ì •
```

### 2. ë²„ì „ ê´€ë¦¬

```python
# ë°ì´í„° ë²„ì „ì„ ëª…ì‹œ
metadata = {
    "version": "1.0",
    "created_at": "2026-01-10",
    "preprocessing_config": {...}
}
```

### 3. ì¦ë¶„ ì—…ë°ì´íŠ¸

```python
# ìƒˆë¡œìš´ ë°ì´í„°ë§Œ ì¶”ê°€
# ê¸°ì¡´ ë°ì´í„°ëŠ” ìœ ì§€
```

---

ì´ í”„ë¡œí† ì½œì„ ë”°ë¼ íš¨ìœ¨ì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ê³µìœ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸš€
