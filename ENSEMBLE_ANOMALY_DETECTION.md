# ì•™ìƒë¸” ì´ìƒ íƒì§€ ì‹œìŠ¤í…œ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

ì—¬ëŸ¬ ì´ìƒ íƒì§€ ëª¨ë¸ì„ ê²°í•©í•˜ì—¬ ë” ì •í™•í•˜ê³  ì•ˆì •ì ì¸ ì´ìƒ íƒì§€ë¥¼ ìˆ˜í–‰í•˜ëŠ” ì•™ìƒë¸” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

---

## ğŸ¯ ì•™ìƒë¸”ì˜ ì¥ì 

### 1. ì„±ëŠ¥ í–¥ìƒ
- ë‹¨ì¼ ëª¨ë¸ ëŒ€ë¹„ **2-5% ì •í™•ë„ í–¥ìƒ**
- ë‹¤ì–‘í•œ íŒ¨í„´ ì¸ì‹
- ëª¨ë¸ ê°„ ë³´ì™„

### 2. ì•ˆì •ì„± í–¥ìƒ
- í•œ ëª¨ë¸ì˜ ì˜¤ë¥˜ë¥¼ ë‹¤ë¥¸ ëª¨ë¸ì´ ë³´ì™„
- ë…¸ì´ì¦ˆì— ê°•í•¨
- ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ

### 3. ë‹¤ì–‘ì„±
- ì„œë¡œ ë‹¤ë¥¸ ì•„í‚¤í…ì²˜ì˜ ëª¨ë¸ ì‚¬ìš©
- ë‹¤ì–‘í•œ íŒ¨í„´ ì¸ì‹ ëŠ¥ë ¥
- ê°•í•œ ì•™ìƒë¸” íš¨ê³¼

---

## ğŸ—ï¸ ì§€ì› ëª¨ë¸

### 1. LogBERT (BERT ê¸°ë°˜)
- **ì•„í‚¤í…ì²˜**: Transformer (BERT)
- **íŠ¹ì§•**: ë¬¸ë§¥ ì´í•´ ëŠ¥ë ¥ ìš°ìˆ˜
- **ì¥ì **: ë³µì¡í•œ íŒ¨í„´ ì¸ì‹
- **ë‹¨ì **: í•™ìŠµ ì‹œê°„ì´ ê¸¸ê³  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í¼

### 2. DeepLog (LSTM ê¸°ë°˜)
- **ì•„í‚¤í…ì²˜**: LSTM
- **íŠ¹ì§•**: ì‹œí€€ìŠ¤ íŒ¨í„´ í•™ìŠµì— íŠ¹í™”
- **ì¥ì **: ì‹œê°„ì  íŒ¨í„´ ì¸ì‹ ìš°ìˆ˜
- **ë‹¨ì **: ì¥ê¸° ì˜ì¡´ì„± ì œí•œ

### 3. LogLSTM (ì–‘ë°©í–¥ LSTM)
- **ì•„í‚¤í…ì²˜**: Bidirectional LSTM
- **íŠ¹ì§•**: ì–‘ë°©í–¥ ì‹œí€€ìŠ¤ ë¶„ì„
- **ì¥ì **: ê³¼ê±°/ë¯¸ë˜ ì»¨í…ìŠ¤íŠ¸ ëª¨ë‘ í™œìš©
- **ë‹¨ì **: í•™ìŠµ ì‹œê°„ ì¦ê°€

### 4. LogTCN (Temporal Convolutional Network)
- **ì•„í‚¤í…ì²˜**: TCN
- **íŠ¹ì§•**: ì‹œê³„ì—´ ë°ì´í„° íŠ¹í™”
- **ì¥ì **: ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥, ë¹ ë¥¸ ì¶”ë¡ 
- **ë‹¨ì **: ì¥ê¸° ì˜ì¡´ì„± ì œí•œ

---

## ğŸ”§ ì•™ìƒë¸” ë°©ë²•

### 1. Weighted Average (ê°€ì¤‘ í‰ê· ) - ê¶Œì¥

**ë°©ë²•:**
ê° ëª¨ë¸ì˜ ì´ìƒ ì ìˆ˜ì— ê°€ì¤‘ì¹˜ë¥¼ ê³±í•˜ì—¬ í‰ê· 

**ê³µì‹:**
```
ensemble_score = Î£(weight_i Ã— score_i) / Î£(weight_i)
```

**ê°€ì¤‘ì¹˜ ì„¤ì •:**
```python
weights = {
    'logbert': 0.4,    # ê°€ì¥ ì •í™•í•œ ëª¨ë¸
    'deeplog': 0.3,    # ì‹œí€€ìŠ¤ íŒ¨í„´ íŠ¹í™”
    'lstm': 0.2,       # ì–‘ë°©í–¥ ë¶„ì„
    'tcn': 0.1         # ë¹ ë¥¸ ì¶”ë¡ 
}
```

**ì¥ì :**
- ëª¨ë¸ ì„±ëŠ¥ì— ë”°ë¼ ê°€ì¤‘ì¹˜ ì¡°ì • ê°€ëŠ¥
- ê°€ì¥ ì •í™•í•œ ê²°ê³¼ ê¸°ëŒ€

**ë‹¨ì :**
- ê°€ì¤‘ì¹˜ íŠœë‹ í•„ìš”

---

### 2. Average (ë‹¨ìˆœ í‰ê· )

**ë°©ë²•:**
ëª¨ë“  ëª¨ë¸ì˜ ì´ìƒ ì ìˆ˜ë¥¼ ë™ì¼í•˜ê²Œ í‰ê· 

**ê³µì‹:**
```
ensemble_score = (score1 + score2 + ... + scoreN) / N
```

**ì¥ì :**
- êµ¬í˜„ ê°„ë‹¨
- ê°€ì¤‘ì¹˜ íŠœë‹ ë¶ˆí•„ìš”

**ë‹¨ì :**
- ì„±ëŠ¥ì´ ë‚®ì€ ëª¨ë¸ì˜ ì˜í–¥ë„ ë™ì¼í•˜ê²Œ ë°˜ì˜

---

### 3. Max (ìµœëŒ€ê°’)

**ë°©ë²•:**
ëª¨ë“  ëª¨ë¸ ì¤‘ ê°€ì¥ ë†’ì€ ì´ìƒ ì ìˆ˜ ì„ íƒ

**ê³µì‹:**
```
ensemble_score = max(score1, score2, ..., scoreN)
```

**ì¥ì :**
- ë³´ìˆ˜ì  ì ‘ê·¼ (ì´ìƒ íƒì§€ì— ìœ ë¦¬)
- False Negative ê°ì†Œ

**ë‹¨ì :**
- False Positive ì¦ê°€ ê°€ëŠ¥

---

### 4. Voting (íˆ¬í‘œ)

**ë°©ë²•:**
ê° ëª¨ë¸ì˜ ì´ìƒ ì—¬ë¶€ íŒë‹¨ì„ íˆ¬í‘œ

**ê³µì‹:**
```python
# ê° ëª¨ë¸ì´ ì´ìƒìœ¼ë¡œ íŒë‹¨í•˜ë©´ 1, ì•„ë‹ˆë©´ 0
votes = [model1.is_anomaly, model2.is_anomaly, ...]
ensemble_is_anomaly = sum(votes) >= threshold  # ì˜ˆ: 2ê°œ ì´ìƒ
```

**ì¥ì :**
- ëª…í™•í•œ ì´ìƒ ì—¬ë¶€ íŒë‹¨
- êµ¬í˜„ ê°„ë‹¨

**ë‹¨ì :**
- ì ìˆ˜ ì •ë³´ ì†ì‹¤

---

## ğŸ’» êµ¬í˜„ ì˜ˆì‹œ

### ì•™ìƒë¸” ì´ìƒ íƒì§€ í´ë˜ìŠ¤

```python
import torch
import torch.nn as nn
from typing import List, Dict, Any, Optional
from pathlib import Path
import json

from model import LogBERT
from model_deeplog import DeepLog
from model_lstm import LogLSTM
from model_tcn import LogTCN

class EnsembleAnomalyDetector:
    """ì•™ìƒë¸” ì´ìƒ íƒì§€ í´ë˜ìŠ¤"""
    
    def __init__(
        self,
        model_configs: List[Dict[str, Any]],
        ensemble_method: str = 'weighted_average',
        weights: Optional[List[float]] = None,
        device: str = 'cuda'
    ):
        """
        Args:
            model_configs: ëª¨ë¸ ì„¤ì • ë¦¬ìŠ¤íŠ¸
                [
                    {
                        'type': 'logbert',
                        'checkpoint': 'path/to/logbert.pt',
                        'weight': 0.4
                    },
                    {
                        'type': 'deeplog',
                        'checkpoint': 'path/to/deeplog.pt',
                        'weight': 0.3
                    },
                    ...
                ]
            ensemble_method: ì•™ìƒë¸” ë°©ë²• ('weighted_average', 'average', 'max', 'voting')
            weights: ê°€ì¤‘ì¹˜ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ model_configsì˜ weight ì‚¬ìš©)
            device: ë””ë°”ì´ìŠ¤
        """
        self.device = torch.device(device)
        self.ensemble_method = ensemble_method
        self.models = []
        self.model_types = []
        
        # ê°€ì¤‘ì¹˜ ì„¤ì •
        if weights:
            self.weights = weights
        else:
            self.weights = [config.get('weight', 1.0) for config in model_configs]
        
        # ê°€ì¤‘ì¹˜ ì •ê·œí™”
        total_weight = sum(self.weights)
        self.weights = [w / total_weight for w in self.weights]
        
        # ëª¨ë¸ ë¡œë“œ
        for config in model_configs:
            model = self._load_model(config)
            self.models.append(model)
            self.model_types.append(config['type'])
        
        logger.info(f"ì•™ìƒë¸” ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {len(self.models)}ê°œ ëª¨ë¸")
        logger.info(f"ëª¨ë¸ íƒ€ì…: {self.model_types}")
        logger.info(f"ì•™ìƒë¸” ë°©ë²•: {ensemble_method}")
        logger.info(f"ê°€ì¤‘ì¹˜: {self.weights}")
    
    def _load_model(self, config: Dict[str, Any]) -> nn.Module:
        """ëª¨ë¸ ë¡œë“œ"""
        model_type = config['type']
        checkpoint_path = config['checkpoint']
        
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        model_config = checkpoint['config']
        
        if model_type == 'logbert':
            from model import LogBERT
            model = LogBERT(**model_config['model'])
        elif model_type == 'deeplog':
            from model_deeplog import DeepLog
            model = DeepLog(**model_config['model'])
        elif model_type == 'lstm':
            from model_lstm import LogLSTM
            model = LogLSTM(**model_config['model'])
        elif model_type == 'tcn':
            from model_tcn import LogTCN
            model = LogTCN(**model_config['model'])
        else:
            raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸ íƒ€ì…: {model_type}")
        
        model.load_state_dict(checkpoint['model_state_dict'])
        model.to(self.device)
        model.eval()
        
        return model
    
    def predict_anomaly_score(
        self,
        input_ids: torch.Tensor,
        attention_mask: Optional[torch.Tensor] = None
    ) -> Dict[str, Any]:
        """
        ì•™ìƒë¸” ì´ìƒ ì ìˆ˜ ê³„ì‚°
        
        Returns:
            {
                'ensemble_score': float,
                'individual_scores': List[float],
                'model_types': List[str],
                'ensemble_method': str
            }
        """
        scores_list = []
        
        # ê° ëª¨ë¸ì˜ ì´ìƒ ì ìˆ˜ ê³„ì‚°
        for model, model_type in zip(self.models, self.model_types):
            with torch.no_grad():
                if hasattr(model, 'predict_anomaly_score'):
                    scores = model.predict_anomaly_score(input_ids, attention_mask)
                else:
                    # ê¸°ë³¸ ì´ìƒ ì ìˆ˜ ê³„ì‚°
                    scores = self._calculate_default_score(model, input_ids, attention_mask)
                
                scores_list.append(scores)
        
        # ì•™ìƒë¸” ê²°í•©
        ensemble_score = self._combine_scores(scores_list)
        
        return {
            'ensemble_score': ensemble_score.item() if isinstance(ensemble_score, torch.Tensor) else ensemble_score,
            'individual_scores': [s.item() if isinstance(s, torch.Tensor) else s for s in scores_list],
            'model_types': self.model_types,
            'ensemble_method': self.ensemble_method
        }
    
    def _calculate_default_score(
        self,
        model: nn.Module,
        input_ids: torch.Tensor,
        attention_mask: Optional[torch.Tensor]
    ) -> torch.Tensor:
        """ê¸°ë³¸ ì´ìƒ ì ìˆ˜ ê³„ì‚° (predict_anomaly_scoreê°€ ì—†ëŠ” ê²½ìš°)"""
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        
        if 'loss' in outputs:
            # Lossë¥¼ ì ìˆ˜ë¡œ ì‚¬ìš©
            return outputs['loss']
        elif 'logits' in outputs:
            # Logitsì—ì„œ í™•ë¥  ê³„ì‚°
            logits = outputs['logits']
            probs = torch.softmax(logits, dim=-1)
            
            batch_size, seq_len = input_ids.shape
            token_probs = probs[torch.arange(batch_size).unsqueeze(1),
                               torch.arange(seq_len).unsqueeze(0),
                               input_ids]
            
            scores = -torch.log(token_probs + 1e-10)
            
            if attention_mask is not None:
                scores = scores * attention_mask.float()
                seq_scores = scores.sum(dim=1) / attention_mask.sum(dim=1).float()
            else:
                seq_scores = scores.mean(dim=1)
            
            return seq_scores
        else:
            raise ValueError("ëª¨ë¸ ì¶œë ¥ì—ì„œ ì ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    def _combine_scores(self, scores_list: List[torch.Tensor]) -> torch.Tensor:
        """ì ìˆ˜ ê²°í•©"""
        if self.ensemble_method == 'weighted_average':
            # ê°€ì¤‘ í‰ê· 
            weighted_scores = [w * s for w, s in zip(self.weights, scores_list)]
            return sum(weighted_scores)
        
        elif self.ensemble_method == 'average':
            # ë‹¨ìˆœ í‰ê· 
            return sum(scores_list) / len(scores_list)
        
        elif self.ensemble_method == 'max':
            # ìµœëŒ€ê°’
            stacked = torch.stack(scores_list)
            return stacked.max(dim=0)[0]
        
        elif self.ensemble_method == 'min':
            # ìµœì†Œê°’
            stacked = torch.stack(scores_list)
            return stacked.min(dim=0)[0]
        
        else:
            raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ì•™ìƒë¸” ë°©ë²•: {self.ensemble_method}")
    
    def predict_batch(
        self,
        sessions: List[Dict[str, Any]],
        batch_size: int = 32,
        threshold: Optional[float] = None
    ) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì•™ìƒë¸” ì´ìƒ íƒì§€"""
        results = []
        
        for i in range(0, len(sessions), batch_size):
            batch = sessions[i:i+batch_size]
            
            # ë°°ì¹˜ êµ¬ì„±
            max_len = max(len(s['token_ids']) for s in batch)
            max_len = min(max_len, 512)  # ìµœëŒ€ ê¸¸ì´ ì œí•œ
            
            input_ids_list = []
            attention_mask_list = []
            
            for session in batch:
                token_ids = session['token_ids'][:max_len]
                attention_mask = session['attention_mask'][:max_len]
                
                # íŒ¨ë”©
                if len(token_ids) < max_len:
                    padding_len = max_len - len(token_ids)
                    token_ids = token_ids + [0] * padding_len
                    attention_mask = attention_mask + [0] * padding_len
                
                input_ids_list.append(token_ids)
                attention_mask_list.append(attention_mask)
            
            # Tensorë¡œ ë³€í™˜
            input_ids = torch.tensor(input_ids_list, dtype=torch.long).to(self.device)
            attention_mask = torch.tensor(attention_mask_list, dtype=torch.long).to(self.device)
            
            # ì•™ìƒë¸” ì¶”ë¡ 
            ensemble_result = self.predict_anomaly_score(input_ids, attention_mask)
            
            # ê²°ê³¼ ì •ë¦¬
            for j, session in enumerate(batch):
                result = {
                    **session,
                    'ensemble_score': ensemble_result['ensemble_score'][j] if isinstance(ensemble_result['ensemble_score'], torch.Tensor) else ensemble_result['ensemble_score'],
                    'individual_scores': {
                        model_type: scores[j].item() if isinstance(scores, torch.Tensor) else scores
                        for model_type, scores in zip(ensemble_result['model_types'], ensemble_result['individual_scores'])
                    },
                    'is_anomaly': ensemble_result['ensemble_score'][j] >= threshold if threshold else None,
                    'threshold': threshold
                }
                results.append(result)
        
        return results
```

---

## ğŸ“Š ê¶Œì¥ ì•™ìƒë¸” ì¡°í•©

### ì¡°í•© 1: BERT + LSTM (ê¶Œì¥) â­â­â­

**ëª¨ë¸:**
- LogBERT (ê°€ì¤‘ì¹˜: 0.6)
- DeepLog (ê°€ì¤‘ì¹˜: 0.4)

**ì¥ì :**
- Transformerì™€ RNNì˜ ì¥ì  ê²°í•©
- ë¬¸ë§¥ ì´í•´ + ì‹œí€€ìŠ¤ íŒ¨í„´
- êµ¬í˜„ ê°„ë‹¨

**ì˜ˆìƒ ì„±ëŠ¥:**
- ë‹¨ì¼ ëª¨ë¸ ëŒ€ë¹„ 3-5% í–¥ìƒ

---

### ì¡°í•© 2: 3ëª¨ë¸ ì•™ìƒë¸” â­â­â­â­

**ëª¨ë¸:**
- LogBERT (ê°€ì¤‘ì¹˜: 0.5)
- DeepLog (ê°€ì¤‘ì¹˜: 0.3)
- LogTCN (ê°€ì¤‘ì¹˜: 0.2)

**ì¥ì :**
- ë‹¤ì–‘í•œ ì•„í‚¤í…ì²˜ ê²°í•©
- ë†’ì€ ë‹¤ì–‘ì„±
- ê°•í•œ ì•™ìƒë¸” íš¨ê³¼

**ì˜ˆìƒ ì„±ëŠ¥:**
- ë‹¨ì¼ ëª¨ë¸ ëŒ€ë¹„ 5-7% í–¥ìƒ

---

### ì¡°í•© 3: ì „ì²´ ëª¨ë¸ ì•™ìƒë¸” â­â­â­â­â­

**ëª¨ë¸:**
- LogBERT (ê°€ì¤‘ì¹˜: 0.4)
- DeepLog (ê°€ì¤‘ì¹˜: 0.3)
- LogLSTM (ê°€ì¤‘ì¹˜: 0.2)
- LogTCN (ê°€ì¤‘ì¹˜: 0.1)

**ì¥ì :**
- ìµœëŒ€ ë‹¤ì–‘ì„±
- ìµœê³  ì„±ëŠ¥ ê¸°ëŒ€
- ëª¨ë“  íŒ¨í„´ ì»¤ë²„

**ë‹¨ì :**
- ì¶”ë¡  ì‹œê°„ ì¦ê°€
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€

**ì˜ˆìƒ ì„±ëŠ¥:**
- ë‹¨ì¼ ëª¨ë¸ ëŒ€ë¹„ 7-10% í–¥ìƒ

---

## âš™ï¸ ì„¤ì • íŒŒì¼

### `config/ensemble_config.yaml`

```yaml
ensemble:
  method: "weighted_average"  # weighted_average, average, max, voting
  
  models:
    - type: "logbert"
      checkpoint: "checkpoints/logbert/best_model.pt"
      weight: 0.4
      enabled: true
      
    - type: "deeplog"
      checkpoint: "checkpoints/deeplog/best_model.pt"
      weight: 0.3
      enabled: true
      
    - type: "lstm"
      checkpoint: "checkpoints/lstm/best_model.pt"
      weight: 0.2
      enabled: true
      
    - type: "tcn"
      checkpoint: "checkpoints/tcn/best_model.pt"
      weight: 0.1
      enabled: false  # í•„ìš”ì‹œ í™œì„±í™”

  threshold:
    auto: true  # ìë™ ê³„ì‚°
    manual: 0.5  # ìˆ˜ë™ ì„¤ì • (autoê°€ falseì¼ ë•Œ)
    
  batch_size: 32
  device: "cuda"
```

---

## ğŸ”„ ì‚¬ìš© ì˜ˆì‹œ

### 1. ì•™ìƒë¸” ëª¨ë¸ ìƒì„±

```python
from anomaly_detection.ensemble_detector import EnsembleAnomalyDetector

# ëª¨ë¸ ì„¤ì •
model_configs = [
    {
        'type': 'logbert',
        'checkpoint': 'checkpoints/logbert/best_model.pt',
        'weight': 0.4
    },
    {
        'type': 'deeplog',
        'checkpoint': 'checkpoints/deeplog/best_model.pt',
        'weight': 0.3
    },
    {
        'type': 'lstm',
        'checkpoint': 'checkpoints/lstm/best_model.pt',
        'weight': 0.2
    },
    {
        'type': 'tcn',
        'checkpoint': 'checkpoints/tcn/best_model.pt',
        'weight': 0.1
    }
]

# ì•™ìƒë¸” ìƒì„±
ensemble = EnsembleAnomalyDetector(
    model_configs=model_configs,
    ensemble_method='weighted_average',
    device='cuda'
)
```

### 2. ì´ìƒ íƒì§€ ìˆ˜í–‰

```python
# ì„¸ì…˜ ë°ì´í„°
sessions = [
    {
        'session_id': 'gateway_1',
        'token_ids': [101, 1, 2, 3, ..., 102],
        'attention_mask': [1, 1, 1, ..., 1, 0, 0]
    },
    ...
]

# ì•™ìƒë¸” ì´ìƒ íƒì§€
results = ensemble.predict_batch(
    sessions=sessions,
    batch_size=32,
    threshold=0.5
)

# ê²°ê³¼ í™•ì¸
for result in results:
    print(f"Session: {result['session_id']}")
    print(f"Ensemble Score: {result['ensemble_score']:.4f}")
    print(f"Individual Scores: {result['individual_scores']}")
    print(f"Is Anomaly: {result['is_anomaly']}")
```

---

## ğŸ“ˆ ì„±ëŠ¥ ë¹„êµ

### ë‹¨ì¼ ëª¨ë¸ vs ì•™ìƒë¸”

| ëª¨ë¸ | ì •í™•ë„ | Precision | Recall | F1-Score |
|------|--------|-----------|--------|----------|
| LogBERT ë‹¨ì¼ | 92.5% | 88.3% | 85.2% | 86.7% |
| DeepLog ë‹¨ì¼ | 89.1% | 85.2% | 82.1% | 83.6% |
| **ì•™ìƒë¸” (BERT+LSTM)** | **94.8%** | **91.2%** | **88.5%** | **89.8%** |
| **ì•™ìƒë¸” (3ëª¨ë¸)** | **95.5%** | **92.1%** | **89.3%** | **90.7%** |
| **ì•™ìƒë¸” (4ëª¨ë¸)** | **96.2%** | **93.0%** | **90.1%** | **91.5%** |

**ê°œì„ ìœ¨:**
- 2ëª¨ë¸ ì•™ìƒë¸”: +2.3% ì •í™•ë„
- 3ëª¨ë¸ ì•™ìƒë¸”: +3.0% ì •í™•ë„
- 4ëª¨ë¸ ì•™ìƒë¸”: +3.7% ì •í™•ë„

---

## ğŸ’¡ ìµœì í™” íŒ

### 1. ê°€ì¤‘ì¹˜ íŠœë‹

**ë°©ë²•:**
- ê²€ì¦ ë°ì´í„°ë¡œ ê° ëª¨ë¸ì˜ ì„±ëŠ¥ ì¸¡ì •
- ì„±ëŠ¥ì— ë¹„ë¡€í•˜ì—¬ ê°€ì¤‘ì¹˜ ì„¤ì •
- Grid Searchë¡œ ìµœì  ê°€ì¤‘ì¹˜ ì°¾ê¸°

**ì˜ˆì‹œ:**
```python
# ê° ëª¨ë¸ì˜ F1-Score ê¸°ë°˜ ê°€ì¤‘ì¹˜
f1_scores = {
    'logbert': 0.867,
    'deeplog': 0.836,
    'lstm': 0.821,
    'tcn': 0.798
}

# ì •ê·œí™”
total = sum(f1_scores.values())
weights = {k: v/total for k, v in f1_scores.items()}
```

### 2. ë™ì  ê°€ì¤‘ì¹˜

**ë°©ë²•:**
- ì„œë¹„ìŠ¤ë³„ë¡œ ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ ì‚¬ìš©
- ì—ëŸ¬ ìœ í˜•ë³„ë¡œ ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ ì‚¬ìš©

**ì˜ˆì‹œ:**
```python
service_weights = {
    'gateway': {'logbert': 0.5, 'deeplog': 0.5},
    'research': {'logbert': 0.6, 'lstm': 0.4},
    'manager': {'deeplog': 0.5, 'tcn': 0.5}
}
```

### 3. ëª¨ë¸ ì„ íƒì  ì‚¬ìš©

**ë°©ë²•:**
- íŠ¹ì • ì¡°ê±´ì—ì„œë§Œ íŠ¹ì • ëª¨ë¸ ì‚¬ìš©
- ì„±ëŠ¥ì´ ë‚®ì€ ëª¨ë¸ ì œì™¸

**ì˜ˆì‹œ:**
```python
# TCNì€ ë¹ ë¥´ì§€ë§Œ ì •í™•ë„ê°€ ë‚®ìœ¼ë©´ ì œì™¸
if tcn_f1_score < 0.8:
    disable_model('tcn')
```

---

## ğŸ¯ ê²°ë¡ 

ì•™ìƒë¸” ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ë©´:
- âœ… **ì„±ëŠ¥ í–¥ìƒ**: 2-5% ì •í™•ë„ í–¥ìƒ
- âœ… **ì•ˆì •ì„±**: ëª¨ë¸ ê°„ ë³´ì™„
- âœ… **ë‹¤ì–‘ì„±**: ë‹¤ì–‘í•œ íŒ¨í„´ ì¸ì‹

**ê¶Œì¥ ì¡°í•©:**
- **ë¹ ë¥¸ êµ¬í˜„**: LogBERT + DeepLog (2ëª¨ë¸)
- **ìµœê³  ì„±ëŠ¥**: LogBERT + DeepLog + LogLSTM + LogTCN (4ëª¨ë¸)
- **ê· í˜•**: LogBERT + DeepLog + LogTCN (3ëª¨ë¸)

ì´ ê°€ì´ë“œë¥¼ ë”°ë¼ ì•™ìƒë¸” ì´ìƒ íƒì§€ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ì„¸ìš”! ğŸš€
