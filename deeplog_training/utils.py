#!/usr/bin/env python3
"""
GPU ëª¨ë‹ˆí„°ë§ ë° í•™ìŠµ ìœ í‹¸ë¦¬í‹°
Tesla V100-DGXS-32GB x 4 í™˜ê²½ ìµœì í™”
"""

import os
import time
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List
import subprocess

import torch
import torch.nn as nn

logger = logging.getLogger(__name__)


class GPUMonitor:
    """
    GPU ìƒíƒœ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤
    
    ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰, í™œìš©ë¥ , ì˜¨ë„ ë“±ì„ ì¶”ì í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, log_interval: int = 50):
        """
        Args:
            log_interval: ë¡œê¹… ê°„ê²© (ë°°ì¹˜ ìˆ˜)
        """
        self.log_interval = log_interval
        self.has_nvidia_smi = self._check_nvidia_smi()
        self.num_gpus = torch.cuda.device_count()
        
        logger.info(f"GPU ëª¨ë‹ˆí„° ì´ˆê¸°í™”: {self.num_gpus}ê°œ GPU ê°ì§€")
    
    def _check_nvidia_smi(self) -> bool:
        """nvidia-smi ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        try:
            subprocess.run(
                ['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'],
                capture_output=True,
                check=True
            )
            return True
        except (subprocess.CalledProcessError, FileNotFoundError):
            return False
    
    def get_gpu_memory_info(self) -> Dict[int, Dict[str, float]]:
        """
        ê° GPUì˜ ë©”ëª¨ë¦¬ ì •ë³´ ë°˜í™˜
        
        Returns:
            {gpu_id: {'used': MB, 'total': MB, 'free': MB, 'percent': %}}
        """
        if not torch.cuda.is_available():
            return {}
        
        info = {}
        for i in range(self.num_gpus):
            try:
                mem_allocated = torch.cuda.memory_allocated(i) / 1024**2  # MB
                mem_reserved = torch.cuda.memory_reserved(i) / 1024**2  # MB
                mem_total = torch.cuda.get_device_properties(i).total_memory / 1024**2  # MB
                
                info[i] = {
                    'allocated': mem_allocated,
                    'reserved': mem_reserved,
                    'total': mem_total,
                    'free': mem_total - mem_reserved,
                    'percent': (mem_reserved / mem_total) * 100,
                }
            except Exception as e:
                logger.warning(f"GPU {i} ë©”ëª¨ë¦¬ ì •ë³´ íšë“ ì‹¤íŒ¨: {e}")
        
        return info
    
    def get_gpu_utilization(self) -> Dict[int, Dict[str, Any]]:
        """
        nvidia-smië¥¼ ì‚¬ìš©í•˜ì—¬ GPU í™œìš©ë¥  ì¡°íšŒ
        
        Returns:
            {gpu_id: {'utilization': %, 'temperature': Â°C, 'power': W}}
        """
        if not self.has_nvidia_smi:
            return {}
        
        try:
            result = subprocess.run(
                [
                    'nvidia-smi',
                    '--query-gpu=index,utilization.gpu,temperature.gpu,power.draw',
                    '--format=csv,noheader,nounits'
                ],
                capture_output=True,
                text=True,
                check=True
            )
            
            info = {}
            for line in result.stdout.strip().split('\n'):
                if line:
                    parts = [p.strip() for p in line.split(',')]
                    if len(parts) >= 4:
                        gpu_id = int(parts[0])
                        info[gpu_id] = {
                            'utilization': float(parts[1]) if parts[1] != '[N/A]' else 0,
                            'temperature': float(parts[2]) if parts[2] != '[N/A]' else 0,
                            'power': float(parts[3]) if parts[3] != '[N/A]' else 0,
                        }
            
            return info
            
        except Exception as e:
            logger.debug(f"GPU í™œìš©ë¥  ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def get_gpu_names(self) -> List[str]:
        """GPU ì´ë¦„ ëª©ë¡ ë°˜í™˜"""
        names = []
        for i in range(self.num_gpus):
            try:
                name = torch.cuda.get_device_name(i)
                names.append(name)
            except Exception:
                names.append(f"GPU {i}")
        return names
    
    def log_gpu_status(self, step: int = 0, prefix: str = ""):
        """GPU ìƒíƒœ ë¡œê¹…"""
        if step % self.log_interval != 0:
            return
        
        mem_info = self.get_gpu_memory_info()
        util_info = self.get_gpu_utilization()
        
        log_lines = [f"{prefix}GPU ìƒíƒœ (Step {step}):"]
        
        for gpu_id in range(self.num_gpus):
            mem = mem_info.get(gpu_id, {})
            util = util_info.get(gpu_id, {})
            
            mem_str = f"ë©”ëª¨ë¦¬: {mem.get('allocated', 0):.0f}/{mem.get('total', 0):.0f}MB ({mem.get('percent', 0):.1f}%)"
            util_str = f"í™œìš©ë¥ : {util.get('utilization', 0):.0f}%"
            temp_str = f"ì˜¨ë„: {util.get('temperature', 0):.0f}Â°C"
            power_str = f"ì „ë ¥: {util.get('power', 0):.0f}W"
            
            log_lines.append(f"  GPU {gpu_id}: {mem_str} | {util_str} | {temp_str} | {power_str}")
        
        logger.info("\n".join(log_lines))
    
    def get_summary(self) -> str:
        """GPU ìƒíƒœ ìš”ì•½ ë¬¸ìì—´ ë°˜í™˜"""
        mem_info = self.get_gpu_memory_info()
        util_info = self.get_gpu_utilization()
        
        parts = []
        for gpu_id in range(self.num_gpus):
            mem = mem_info.get(gpu_id, {})
            util = util_info.get(gpu_id, {})
            parts.append(
                f"[{gpu_id}:{mem.get('allocated', 0):.0f}MB|{util.get('utilization', 0):.0f}%]"
            )
        
        return " ".join(parts)


class TrainingTimer:
    """
    í•™ìŠµ ì‹œê°„ ì¸¡ì • ë° ì˜ˆì¸¡ í´ë˜ìŠ¤
    """
    
    def __init__(self, total_steps: Optional[int] = None, total_epochs: Optional[int] = None):
        self.total_steps = total_steps
        self.total_epochs = total_epochs
        
        self.start_time = None
        self.epoch_start_time = None
        self.batch_times = []
        self.epoch_times = []
        
        self._current_step = 0
        self._current_epoch = 0
    
    def start(self):
        """ì „ì²´ í•™ìŠµ ì‹œì‘"""
        self.start_time = time.time()
    
    def start_epoch(self, epoch: int):
        """ì—í­ ì‹œì‘"""
        self._current_epoch = epoch
        self.epoch_start_time = time.time()
        self.batch_times = []
    
    def end_epoch(self) -> float:
        """ì—í­ ì¢…ë£Œ, ì†Œìš” ì‹œê°„ ë°˜í™˜"""
        elapsed = time.time() - self.epoch_start_time
        self.epoch_times.append(elapsed)
        return elapsed
    
    def step(self):
        """ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ"""
        self._current_step += 1
        if self.batch_times:
            self.batch_times.append(time.time())
        else:
            self.batch_times = [time.time()]
    
    def get_batch_time(self) -> float:
        """í‰ê·  ë°°ì¹˜ ì²˜ë¦¬ ì‹œê°„"""
        if len(self.batch_times) < 2:
            return 0.0
        
        times = []
        for i in range(1, len(self.batch_times)):
            times.append(self.batch_times[i] - self.batch_times[i-1])
        
        return sum(times) / len(times) if times else 0.0
    
    def get_elapsed_time(self) -> float:
        """ì „ì²´ ê²½ê³¼ ì‹œê°„"""
        if self.start_time is None:
            return 0.0
        return time.time() - self.start_time
    
    def get_eta(self) -> Optional[float]:
        """ì˜ˆìƒ ë‚¨ì€ ì‹œê°„ (ì´ˆ)"""
        if self.total_steps is None or self._current_step == 0:
            return None
        
        elapsed = self.get_elapsed_time()
        rate = self._current_step / elapsed
        remaining_steps = self.total_steps - self._current_step
        
        return remaining_steps / rate if rate > 0 else None
    
    def format_time(self, seconds: float) -> str:
        """ì´ˆë¥¼ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        if seconds < 60:
            return f"{seconds:.1f}s"
        elif seconds < 3600:
            return f"{seconds/60:.1f}m"
        else:
            hours = int(seconds // 3600)
            minutes = int((seconds % 3600) // 60)
            return f"{hours}h {minutes}m"
    
    def get_summary(self) -> Dict[str, str]:
        """ì‹œê°„ ì •ë³´ ìš”ì•½"""
        elapsed = self.get_elapsed_time()
        eta = self.get_eta()
        batch_time = self.get_batch_time()
        
        return {
            'elapsed': self.format_time(elapsed),
            'eta': self.format_time(eta) if eta else 'N/A',
            'batch_time': f"{batch_time*1000:.1f}ms" if batch_time > 0 else 'N/A',
            'throughput': f"{1/batch_time:.1f} batch/s" if batch_time > 0 else 'N/A',
        }


class EarlyStopping:
    """
    Early Stopping êµ¬í˜„
    """
    
    def __init__(
        self,
        patience: int = 5,
        min_delta: float = 0.0001,
        mode: str = 'min',
        restore_best: bool = True,
    ):
        """
        Args:
            patience: ê°œì„  ì—†ì´ ì§€ì†ë  ìˆ˜ ìˆëŠ” ì—í­ ìˆ˜
            min_delta: ê°œì„ ìœ¼ë¡œ ê°„ì£¼ë˜ëŠ” ìµœì†Œ ë³€í™”ëŸ‰
            mode: 'min' (loss ê°ì†Œ) ë˜ëŠ” 'max' (accuracy ì¦ê°€)
            restore_best: ìµœê³  ëª¨ë¸ ë³µì› ì—¬ë¶€
        """
        self.patience = patience
        self.min_delta = min_delta
        self.mode = mode
        self.restore_best = restore_best
        
        self.best_score = float('inf') if mode == 'min' else float('-inf')
        self.best_epoch = 0
        self.counter = 0
        self.best_state_dict = None
        self.stopped = False
    
    def __call__(self, score: float, model: nn.Module, epoch: int) -> bool:
        """
        Early Stopping ì²´í¬
        
        Args:
            score: í˜„ì¬ ì ìˆ˜ (loss ë˜ëŠ” metric)
            model: ëª¨ë¸
            epoch: í˜„ì¬ ì—í­
        
        Returns:
            True if í•™ìŠµ ì¤‘ë‹¨ í•„ìš”
        """
        if self.mode == 'min':
            is_better = score < (self.best_score - self.min_delta)
        else:
            is_better = score > (self.best_score + self.min_delta)
        
        if is_better:
            self.best_score = score
            self.best_epoch = epoch
            self.counter = 0
            
            if self.restore_best:
                # ìµœê³  ëª¨ë¸ ìƒíƒœ ì €ì¥
                if isinstance(model, nn.DataParallel):
                    self.best_state_dict = {k: v.cpu().clone() for k, v in model.module.state_dict().items()}
                else:
                    self.best_state_dict = {k: v.cpu().clone() for k, v in model.state_dict().items()}
            
            logger.info(f"âœ… ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥: {score:.6f} (Epoch {epoch})")
        else:
            self.counter += 1
            logger.info(f"âš ï¸ ê°œì„  ì—†ìŒ: {self.counter}/{self.patience} (ìµœê³ : {self.best_score:.6f} @ Epoch {self.best_epoch})")
            
            if self.counter >= self.patience:
                self.stopped = True
                logger.warning(f"ğŸ›‘ Early Stopping! {self.patience} ì—í­ ë™ì•ˆ ê°œì„  ì—†ìŒ")
                return True
        
        return False
    
    def restore_best_weights(self, model: nn.Module):
        """ìµœê³  ëª¨ë¸ ê°€ì¤‘ì¹˜ ë³µì›"""
        if self.best_state_dict is not None:
            if isinstance(model, nn.DataParallel):
                model.module.load_state_dict(self.best_state_dict)
            else:
                model.load_state_dict(self.best_state_dict)
            logger.info(f"ìµœê³  ëª¨ë¸ ë³µì›: Epoch {self.best_epoch}, Score: {self.best_score:.6f}")


class AverageMeter:
    """í‰ê· ê°’ ì¶”ì """
    
    def __init__(self, name: str = ""):
        self.name = name
        self.reset()
    
    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0
    
    def update(self, val: float, n: int = 1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count if self.count > 0 else 0
    
    def __str__(self):
        return f"{self.name}: {self.avg:.4f}"


def get_lr_scheduler(optimizer, config: Dict[str, Any], total_steps: int):
    """
    í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„±
    
    Args:
        optimizer: ì˜µí‹°ë§ˆì´ì €
        config: í•™ìŠµ ì„¤ì •
        total_steps: ì´ í•™ìŠµ ìŠ¤í… ìˆ˜
    
    Returns:
        í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
    """
    scheduler_type = config.get('scheduler_type', 'cosine')
    min_lr = float(config.get('min_lr', 1e-6))
    warmup_steps = config.get('warmup_steps', 1000)
    
    if scheduler_type == 'cosine':
        from torch.optim.lr_scheduler import CosineAnnealingLR
        scheduler = CosineAnnealingLR(
            optimizer,
            T_max=total_steps - warmup_steps,
            eta_min=min_lr
        )
    elif scheduler_type == 'step':
        from torch.optim.lr_scheduler import StepLR
        scheduler = StepLR(
            optimizer,
            step_size=total_steps // 10,
            gamma=0.5
        )
    elif scheduler_type == 'reduce_on_plateau':
        from torch.optim.lr_scheduler import ReduceLROnPlateau
        scheduler = ReduceLROnPlateau(
            optimizer,
            mode='min',
            factor=0.5,
            patience=3,
            min_lr=min_lr
        )
    else:
        scheduler = None
    
    # ì›Œë°ì—… ìŠ¤ì¼€ì¤„ëŸ¬ (Linear warmup)
    if warmup_steps > 0 and scheduler is not None:
        from torch.optim.lr_scheduler import LambdaLR, SequentialLR
        
        def warmup_lambda(step):
            if step < warmup_steps:
                return float(step) / float(max(1, warmup_steps))
            return 1.0
        
        warmup_scheduler = LambdaLR(optimizer, warmup_lambda)
        
        # PyTorch 2.0+ SequentialLR ì‚¬ìš©
        try:
            scheduler = SequentialLR(
                optimizer,
                schedulers=[warmup_scheduler, scheduler],
                milestones=[warmup_steps]
            )
        except AttributeError:
            # PyTorch ì´ì „ ë²„ì „ í˜¸í™˜
            logger.warning("SequentialLR ë¯¸ì§€ì›, ì›Œë°ì—… ì—†ì´ ì§„í–‰")
    
    return scheduler


def setup_logging(log_file: Optional[str] = None, level: int = logging.INFO):
    """
    ë¡œê¹… ì„¤ì •
    
    Args:
        log_file: ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
        level: ë¡œê¹… ë ˆë²¨
    """
    handlers = [logging.StreamHandler()]
    
    if log_file:
        os.makedirs(os.path.dirname(log_file), exist_ok=True)
        handlers.append(logging.FileHandler(log_file, encoding='utf-8'))
    
    logging.basicConfig(
        level=level,
        format='%(asctime)s | %(levelname)s | %(name)s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S',
        handlers=handlers,
        force=True
    )


def print_training_banner(config: Dict[str, Any], num_samples: int = 0):
    """í•™ìŠµ ì‹œì‘ ë°°ë„ˆ ì¶œë ¥"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         DeepLog Training Started                              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
"""
    
    model_config = config.get('model', {})
    training_config = config.get('training', {})
    
    info_lines = [
        f"â•‘  Model: DeepLog (LSTM)                                                       â•‘",
        f"â•‘  - Vocab Size: {model_config.get('vocab_size', 10000):,}                                                          â•‘",
        f"â•‘  - Hidden Size: {model_config.get('hidden_size', 256)}                                                            â•‘",
        f"â•‘  - LSTM Layers: {model_config.get('num_layers', 2)}                                                              â•‘",
        f"â•‘  - Embedding Dim: {model_config.get('embedding_dim', 128)}                                                          â•‘",
        f"â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£",
        f"â•‘  Training Configuration:                                                      â•‘",
        f"â•‘  - Batch Size: {training_config.get('batch_size', 64)}                                                            â•‘",
        f"â•‘  - Learning Rate: {training_config.get('learning_rate', 0.001)}                                                       â•‘",
        f"â•‘  - Epochs: {training_config.get('num_epochs', 50)}                                                                 â•‘",
        f"â•‘  - Samples: {num_samples:,}                                                            â•‘",
        f"â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£",
        f"â•‘  GPU Configuration:                                                           â•‘",
        f"â•‘  - Device Count: {torch.cuda.device_count()}                                                              â•‘",
    ]
    
    for i in range(torch.cuda.device_count()):
        name = torch.cuda.get_device_name(i)
        mem = torch.cuda.get_device_properties(i).total_memory / 1024**3
        info_lines.append(f"â•‘  - GPU {i}: {name[:40]:40s} ({mem:.0f}GB)     â•‘")
    
    info_lines.append("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    print(banner + "\n".join(info_lines))
